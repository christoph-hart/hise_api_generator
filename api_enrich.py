#!/usr/bin/env python3
"""
API Enrichment Pipeline CLI

Produces a comprehensive api_reference.json from Doxygen XML, AI-generated
analysis, project examples, and manual overrides.

Subcommands:
    phase0   - Parse Doxygen XML → base JSON (mechanical)
    prepare  - Print worklist of unscanned classes/methods
    merge    - Merge all phases → output/api_reference.json
    preview  - Generate HTML preview pages from merged JSON

Usage:
    python api_enrich.py phase0
    python api_enrich.py prepare
    python api_enrich.py merge
    python api_enrich.py preview [ClassName]
"""

import argparse
import json
import os
import re
import shutil
import sys
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from html import escape as html_escape
from pathlib import Path

# ---------------------------------------------------------------------------
# Paths (relative to this script's directory)
# ---------------------------------------------------------------------------

SCRIPT_DIR = Path(__file__).resolve().parent
XML_SELECTION_DIR = SCRIPT_DIR / "xml" / "selection"
ENRICHMENT_DIR = SCRIPT_DIR / "enrichment"
BASE_DIR = ENRICHMENT_DIR / "base"
PHASE1_DIR = ENRICHMENT_DIR / "phase1"
PHASE2_DIR = ENRICHMENT_DIR / "phase2"
PHASE3_DIR = ENRICHMENT_DIR / "phase3"
PHASE4_AUTO_DIR = ENRICHMENT_DIR / "phase4" / "auto"
PHASE4_MANUAL_DIR = ENRICHMENT_DIR / "phase4" / "manual"
OUTPUT_DIR = ENRICHMENT_DIR / "output"
SCANNED_FILE = ENRICHMENT_DIR / "phase1_scanned.txt"

# ---------------------------------------------------------------------------
# Category mapping: friendly class name → category
# Derived from batchCreate.bat rename mappings.
# ---------------------------------------------------------------------------

CATEGORY_MAP = {
    # namespace — global API namespaces
    "Array": "namespace",
    "Colours": "namespace",
    "Console": "namespace",
    "Content": "namespace",
    "Date": "namespace",
    "Engine": "namespace",
    "FileSystem": "namespace",
    "Math": "namespace",
    "Message": "namespace",
    "ModuleIds": "namespace",
    "Sampler": "namespace",
    "Server": "namespace",
    "Settings": "namespace",
    "String": "namespace",
    "Synth": "namespace",
    "Threads": "namespace",
    "TransportHandler": "namespace",

    # object — instances obtained via factory methods or module references
    "AudioFile": "object",
    "AudioSampleProcessor": "object",
    "BackgroundTask": "object",
    "BeatportManager": "object",
    "Broadcaster": "object",
    "Buffer": "object",
    "Builder": "object",
    "ChildSynth": "object",
    "ComplexGroupManager": "object",
    "ContainerChild": "object",
    "DisplayBuffer": "object",
    "DisplayBufferSource": "object",
    "Download": "object",
    "DspModule": "object",
    "Effect": "object",
    "ErrorHandler": "object",
    "Expansion": "object",
    "ExpansionHandler": "object",
    "FFT": "object",
    "File": "object",
    "FixObjectArray": "object",
    "FixObjectFactory": "object",
    "FixObjectStack": "object",
    "GlobalCable": "object",
    "GlobalRoutingManager": "object",
    "Graphics": "object",
    "LorisManager": "object",
    "MacroHandler": "object",
    "MarkdownRenderer": "object",
    "MessageHolder": "object",
    "MidiAutomationHandler": "object",
    "MidiList": "object",
    "MidiPlayer": "object",
    "MidiProcessor": "object",
    "Modifiers": "object",
    "Modulator": "object",
    "NeuralNetwork": "object",
    "Path": "object",
    "PresetStorage": "object",
    "Rectangle": "object",
    "RoutingMatrix": "object",
    "Sample": "object",
    "ScriptLookAndFeel": "object",
    "ScriptModulationMatrix": "object",
    "ScriptShader": "object",
    "SliderPackData": "object",
    "SliderPackProcessor": "object",
    "SlotFX": "object",
    "Table": "object",
    "TableProcessor": "object",
    "ThreadSafeStorage": "object",
    "Timer": "object",
    "Unlocker": "object",
    "UnorderedStack": "object",
    "UserPresetHandler": "object",
    "WavetableController": "object",

    # component — UI components created via Content.addX()
    "ScriptAudioWaveform": "component",
    "ScriptButton": "component",
    "ScriptComboBox": "component",
    "ScriptDynamicContainer": "component",
    "ScriptFloatingTile": "component",
    "ScriptImage": "component",
    "ScriptLabel": "component",
    "ScriptMultipageDialog": "component",
    "ScriptPanel": "component",
    "ScriptSlider": "component",
    "ScriptSliderPack": "component",
    "ScriptTable": "component",
    "ScriptWebView": "component",
    "ScriptedViewport": "component",

    # component — not generated by last Doxygen run but present in batchCreate.bat
    "ModulatorMeter": "component",
    "ScriptedPlotter": "component",

    # scriptnode — ScriptNode DSP classes
    "Connection": "scriptnode",
    "DspNetwork": "scriptnode",
    "NetworkTest": "scriptnode",
    "Node": "scriptnode",
    "Parameter": "scriptnode",
}

# ---------------------------------------------------------------------------
# Minimal object tokens: short variable names for method minimalExample
# ---------------------------------------------------------------------------

MINIMAL_OBJECT_TOKEN = {
    # namespace -- empty token (methods use ClassName.method() directly)
    "Array": "",
    "Colours": "",
    "Console": "",
    "Content": "",
    "Date": "",
    "Engine": "",
    "FileSystem": "",
    "Math": "",
    "Message": "",
    "ModuleIds": "",
    "Sampler": "",
    "Server": "",
    "Settings": "",
    "String": "",
    "Synth": "",
    "Threads": "",
    "TransportHandler": "",

    # component -- Interface Designer default IDs
    "ScriptAudioWaveform": "AudioWaveform1",
    "ScriptButton": "Button1",
    "ScriptComboBox": "ComboBox1",
    "ScriptDynamicContainer": "Container1",
    "ScriptFloatingTile": "FloatingTile1",
    "ScriptImage": "Image1",
    "ScriptLabel": "Label1",
    "ScriptModulationMatrix": "ModMatrix1",
    "ScriptMultipageDialog": "Dialog1",
    "ScriptPanel": "Panel1",
    "ScriptSlider": "Knob1",
    "ScriptSliderPack": "SliderPack1",
    "ScriptTable": "Table1",
    "ScriptWebView": "WebView1",
    "ScriptedViewport": "Viewport1",
    "ModulatorMeter": "Meter1",
    "ScriptedPlotter": "Plotter1",

    # object -- short abbreviations
    "AudioFile": "af",
    "AudioSampleProcessor": "asp",
    "BackgroundTask": "task",
    "BeatportManager": "bp",
    "Broadcaster": "bc",
    "Buffer": "buf",
    "Builder": "b",
    "ChildSynth": "cs",
    "ComplexGroupManager": "cgm",
    "ContainerChild": "cc",
    "DisplayBuffer": "db",
    "DisplayBufferSource": "dbs",
    "Download": "dl",
    "DspModule": "dsp",
    "Effect": "fx",
    "ErrorHandler": "eh",
    "Expansion": "exp",
    "ExpansionHandler": "exh",
    "FFT": "fft",
    "File": "f",
    "FixObjectArray": "foa",
    "FixObjectFactory": "fof",
    "FixObjectStack": "fos",
    "GlobalCable": "gc",
    "GlobalRoutingManager": "grm",
    "Graphics": "g",
    "LorisManager": "lm",
    "MacroHandler": "mh",
    "MarkdownRenderer": "mr",
    "MessageHolder": "msg",
    "MidiAutomationHandler": "mah",
    "MidiList": "ml",
    "MidiPlayer": "mp",
    "MidiProcessor": "mpr",
    "Modifiers": "mod",
    "Modulator": "m",
    "NeuralNetwork": "nn",
    "Path": "p",
    "Rectangle": "rect",
    "RoutingMatrix": "rm",
    "Sample": "s",
    "ScriptLookAndFeel": "laf",
    "ScriptShader": "sh",
    "SliderPackData": "spd",
    "SliderPackProcessor": "spp",
    "SlotFX": "sfx",
    "Table": "tbl",
    "TableProcessor": "tp",
    "ThreadSafeStorage": "tss",
    "Timer": "t",
    "Unlocker": "ul",
    "UnorderedStack": "us",
    "UserPresetHandler": "uph",
    "WavetableController": "wtc",

    # scriptnode -- short abbreviations
    "Connection": "con",
    "DspNetwork": "net",
    "NetworkTest": "nt",
    "Node": "n",
    "Parameter": "par",
}

# ---------------------------------------------------------------------------
# Filtering: infrastructure method exclusion
# ---------------------------------------------------------------------------

# Method names that are always infrastructure, even if they have descriptions
INFRASTRUCTURE_METHODS = {
    "getObjectName", "getClassName", "allowIllegalCallsOnAudioThread",
    "setDebugLocation", "timerCallback", "allowRefCount",
    "isControlCallbackPending",       # REST API internal (ScriptComponent)
    "updateContentPropertyInternal",  # Internal property update (ScriptComponent)
}

# C++ type substrings that indicate a non-scriptable (infrastructure) method.
# If any parameter type or the return type contains one of these, the method
# is excluded from the scripting API surface.
NON_SCRIPTABLE_TYPE_PATTERNS = [
    "Component",
    "MouseEvent",
    "HiseJavascriptEngine",
    "ValueTree",
    "DebugableObjectBase",
    "NotificationType",
    "KeyPress",
    "ZLevelListener",
    "ProfileCollection",
    "WeakCallbackHolder",
    "SubComponentListener",
    "NativeFunctionArgs",
    "Identifier",
    "Location",
]

# ---------------------------------------------------------------------------
# C++ type normalization for Phase 0 output
# ---------------------------------------------------------------------------

TYPE_NORMALIZATIONS = {
    "const String &": "String",
    "const String&": "String",
    "String &": "String",
    "String&": "String",
    "const var &": "var",
    "const var&": "var",
    "var &": "var",
    "var&": "var",
}


def normalize_cpp_type(raw_type: str) -> str:
    """Normalize a C++ type string for the base JSON output."""
    t = raw_type.strip()
    # Apply exact normalizations first
    if t in TYPE_NORMALIZATIONS:
        return TYPE_NORMALIZATIONS[t]
    # Strip leading 'const ' and trailing ' &' / '&' for remaining types
    t = re.sub(r"^const\s+", "", t)
    t = re.sub(r"\s*&$", "", t)
    return t.strip()


def contains_non_scriptable_type(type_str: str) -> bool:
    """Check if a type string contains a non-scriptable C++ type."""
    for pattern in NON_SCRIPTABLE_TYPE_PATTERNS:
        if pattern in type_str:
            return True
    return False


# ---------------------------------------------------------------------------
# XML text extraction helpers
# ---------------------------------------------------------------------------

def get_text_content(element) -> str:
    """Recursively extract all text from an XML element and its children."""
    if element is None:
        return ""
    parts = []
    if element.text:
        parts.append(element.text)
    for child in element:
        parts.append(get_text_content(child))
        if child.tail:
            parts.append(child.tail)
    return "".join(parts).strip()


def get_description(memberdef) -> str:
    """Extract the description text from a memberdef's detaileddescription."""
    detailed = memberdef.find("detaileddescription")
    if detailed is None:
        return ""
    return get_text_content(detailed)


# ===================================================================
# PHASE 0: Doxygen XML → Base JSON
# ===================================================================

def run_phase0():
    """Parse all Doxygen XML files in xml/selection/ and produce base JSON."""
    if not XML_SELECTION_DIR.is_dir():
        print(f"ERROR: XML selection directory not found: {XML_SELECTION_DIR}")
        sys.exit(1)

    BASE_DIR.mkdir(parents=True, exist_ok=True)

    xml_files = sorted(XML_SELECTION_DIR.glob("*.xml"))
    if not xml_files:
        print(f"ERROR: No XML files found in {XML_SELECTION_DIR}")
        sys.exit(1)

    total_classes = 0
    total_methods = 0
    skipped_infra = 0

    for xml_path in xml_files:
        class_name = xml_path.stem  # e.g., "Console" from "Console.xml"

        # Skip files not in our category map (shouldn't happen, but be safe)
        if class_name not in CATEGORY_MAP:
            print(f"  WARNING: {class_name} not in category map, skipping")
            continue

        try:
            tree = ET.parse(xml_path)
        except ET.ParseError:
            # Some Doxygen XML files contain invalid characters (e.g., degree
            # symbol in Math.xml). Re-read as bytes, strip non-XML chars, retry.
            try:
                raw = xml_path.read_bytes()
                # Strip bytes outside the valid XML 1.0 character range
                cleaned = bytes(b for b in raw if b == 0x09 or b == 0x0A
                                or b == 0x0D or 0x20 <= b < 0x7F)
                tree = ET.ElementTree(ET.fromstring(cleaned))
            except Exception as e2:
                print(f"  ERROR: Failed to parse {xml_path} even after "
                      f"cleaning: {e2}")
                continue

        root = tree.getroot()
        compounddef = root.find("compounddef")
        if compounddef is None:
            print(f"  WARNING: No compounddef in {xml_path}, skipping")
            continue

        # Class-level description
        class_desc = get_description(compounddef)

        # Collect public methods
        methods = {}
        for sectiondef in compounddef.findall("sectiondef"):
            kind = sectiondef.get("kind", "")
            if kind not in ("public-func", "public-static-func"):
                continue

            for memberdef in sectiondef.findall("memberdef"):
                if memberdef.get("kind") != "function":
                    continue

                name = get_text_content(memberdef.find("name"))
                return_type_raw = get_text_content(memberdef.find("type"))

                # --- Exclusion filters ---

                # 1. Skip constructors (empty return type) and destructors
                if not return_type_raw or name.startswith("~"):
                    continue

                # 2. Skip known infrastructure method names
                if name in INFRASTRUCTURE_METHODS:
                    skipped_infra += 1
                    continue

                # 3. Skip methods with empty descriptions
                desc = get_description(memberdef)
                if not desc:
                    skipped_infra += 1
                    continue

                # 4. Skip methods with non-scriptable types in return or params
                if contains_non_scriptable_type(return_type_raw):
                    skipped_infra += 1
                    continue

                param_has_non_scriptable = False
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    if contains_non_scriptable_type(param_type_raw):
                        param_has_non_scriptable = True
                        break
                if param_has_non_scriptable:
                    skipped_infra += 1
                    continue

                # --- Extract method data ---

                return_type = normalize_cpp_type(return_type_raw)

                parameters = []
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    param_name_el = param.find("declname")
                    param_name = get_text_content(param_name_el) if param_name_el is not None else ""
                    param_type = normalize_cpp_type(param_type_raw)

                    if param_name:  # Skip unnamed parameters
                        parameters.append({
                            "name": param_name,
                            "type": param_type,
                        })

                # Build signature string
                param_strs = [f"{p['type']} {p['name']}" for p in parameters]
                signature = f"{return_type} {name}({', '.join(param_strs)})"

                methods[name] = {
                    "signature": signature,
                    "returnType": return_type,
                    "description": desc,
                    "parameters": parameters,
                }

                total_methods += 1

        # Write base JSON
        base_json = {
            "className": class_name,
            "category": CATEGORY_MAP[class_name],
            "description": class_desc,
            "methods": methods,
        }

        output_path = BASE_DIR / f"{class_name}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(base_json, f, indent=2, ensure_ascii=False)

        total_classes += 1

    print(f"Phase 0 complete:")
    print(f"  Classes processed: {total_classes}")
    print(f"  Methods extracted: {total_methods}")
    print(f"  Infrastructure methods filtered: {skipped_infra}")
    print(f"  Output: {BASE_DIR}")


# ===================================================================
# PREPARE: Print worklist of unscanned classes/methods
# ===================================================================

def _get_phase4_authored(class_name: str) -> tuple:
    """Return (auto_set, manual_set, has_auto_readme, has_manual_readme)
    for a given class, checking both phase4/auto and phase4/manual dirs."""
    auto_set = set()
    manual_set = set()
    has_auto_readme = False
    has_manual_readme = False

    auto_dir = PHASE4_AUTO_DIR / class_name
    manual_dir = PHASE4_MANUAL_DIR / class_name

    if auto_dir.is_dir():
        has_auto_readme = (auto_dir / "Readme.md").is_file()
        for md_file in auto_dir.glob("*.md"):
            if md_file.name.lower() != "readme.md":
                auto_set.add(md_file.stem.lower())

    if manual_dir.is_dir():
        has_manual_readme = (manual_dir / "Readme.md").is_file()
        for md_file in manual_dir.glob("*.md"):
            if md_file.name.lower() != "readme.md":
                manual_set.add(md_file.stem.lower())

    return auto_set, manual_set, has_auto_readme, has_manual_readme


def run_prepare():
    """Read base JSON and scanned manifest, print unscanned worklist."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    # Read scanned manifest
    scanned = set()
    if SCANNED_FILE.is_file():
        with open(SCANNED_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    scanned.add(line)

    # Read all base JSON files
    total_remaining = 0
    total_scanned = 0
    worklist = []

    # Phase 4 tracking
    p4_total_needed = 0
    p4_total_auto = 0
    p4_total_manual = 0
    p4_worklist = []

    for json_path in sorted(BASE_DIR.glob("*.json")):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        class_name = data["className"]
        methods = data.get("methods", {})

        # Phase 1 worklist
        unscanned_methods = []
        for method_name in sorted(methods.keys()):
            key = f"{class_name}.{method_name}"
            if key in scanned:
                total_scanned += 1
            else:
                unscanned_methods.append(method_name)
                total_remaining += 1

        if unscanned_methods:
            worklist.append((class_name, data.get("category", "?"), unscanned_methods))

        # Phase 4 worklist -- only for classes that have Phase 1 data
        p1_dir = PHASE1_DIR / class_name
        if p1_dir.is_dir():
            auto_set, manual_set, has_auto_readme, has_manual_readme = \
                _get_phase4_authored(class_name)
            authored = auto_set | manual_set
            needs_docs = []
            for method_name in sorted(methods.keys()):
                if method_name.lower() not in authored:
                    needs_docs.append(method_name)
                    p4_total_needed += 1
                elif method_name.lower() in manual_set:
                    p4_total_manual += 1
                else:
                    p4_total_auto += 1

            needs_readme = not has_auto_readme and not has_manual_readme
            if needs_docs or needs_readme:
                p4_worklist.append((class_name, needs_readme, needs_docs))

    # Print Phase 1 worklist
    if not worklist:
        print("Phase 1: All methods scanned.")
        print(f"  Total scanned: {total_scanned}")
    else:
        print(f"Phase 1: {total_remaining} methods remaining across {len(worklist)} classes")
        print(f"  Already scanned: {total_scanned}")
        print()
        for class_name, category, methods in worklist:
            print(f"  {class_name} [{category}] -- {len(methods)} methods:")
            for m in methods:
                print(f"    - {m}")
            print()

    # Print Phase 4 worklist
    print()
    if not p4_worklist:
        print("Phase 4: All enriched classes have userDocs.")
        print(f"  Auto: {p4_total_auto}, Manual: {p4_total_manual}")
    else:
        print(f"Phase 4: {p4_total_needed} methods need userDocs across {len(p4_worklist)} classes")
        print(f"  Already authored: {p4_total_auto} auto, {p4_total_manual} manual")
        print()
        for class_name, needs_readme, methods in p4_worklist:
            readme_note = " (+ Readme.md)" if needs_readme else ""
            print(f"  {class_name} -- {len(methods)} methods{readme_note}")
        print()


# ===================================================================
# MERGE: Combine all phases → output/api_reference.json
# ===================================================================

# --- Markdown parsing utilities ---

def parse_readme_md(filepath: Path) -> dict:
    """Parse a Phase 1/3 Readme.md into a structured dict.

    Expected sections: Brief, Purpose, Details, obtainedVia, Constants,
    Dynamic Constants, Common Mistakes, codeExample, Alternatives,
    Related Preprocessors.
    """
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    result = {}

    # Extract sections by ## headings
    sections = split_by_headings(content, level=2)

    if "Brief" in sections:
        result["brief"] = sections["Brief"].strip()

    if "Purpose" in sections:
        result["purpose"] = sections["Purpose"].strip()

    if "Details" in sections:
        details = sections["Details"].strip()
        if details:
            result["details"] = details

    if "obtainedVia" in sections:
        text = sections["obtainedVia"].strip()
        # Strip backticks if wrapped
        text = text.strip("`")
        result["obtainedVia"] = text

    if "minimalObjectToken" in sections:
        # First non-empty line, stripped of backticks and parenthetical notes
        for line in sections["minimalObjectToken"].splitlines():
            line = line.strip().strip("`")
            if line and not line.startswith("("):
                result["minimalObjectToken"] = line
                break

    if "codeExample" in sections:
        result["codeExample"] = extract_code_block(sections["codeExample"])

    if "Alternatives" in sections:
        text = sections["Alternatives"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            result["alternatives"] = text

    if "Related Preprocessors" in sections:
        text = sections["Related Preprocessors"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            # Parse preprocessor names: first backtick-wrapped token per
            # bullet line, or comma-separated plain names as fallback.
            preprocessors = []
            for line in text.splitlines():
                line = line.strip().lstrip("-").strip()
                if not line:
                    continue
                m = re.match(r"`([^`]+)`", line)
                if m:
                    preprocessors.append(m.group(1))
            if not preprocessors:
                preprocessors = [p.strip() for p in text.split(",") if p.strip()]
            if preprocessors:
                result["relatedPreprocessors"] = preprocessors

    if "Constants" in sections:
        result["constants"] = parse_markdown_table(sections["Constants"])

    if "Dynamic Constants" in sections:
        result["dynamicConstants"] = parse_markdown_table(sections["Dynamic Constants"])

    if "Common Mistakes" in sections:
        result["commonMistakes"] = parse_markdown_table(sections["Common Mistakes"])

    if "Diagrams" in sections:
        # Multiple diagrams: h3 sub-sections are diagram ids
        diag_subsections = split_by_headings(sections["Diagrams"], level=3)
        diagrams = []
        for diag_id, diag_text in diag_subsections.items():
            diag_type_m = re.search(r"-\s*\*\*Type:\*\*\s*(\S+)", diag_text)
            diag_brief_m = re.search(
                r"-\s*\*\*Brief:\*\*\s*(.*?)(?=\n-\s*\*\*|\Z)",
                diag_text, re.DOTALL
            )
            diag_desc_m = re.search(
                r"-\s*\*\*Description:\*\*\s*(.*?)(?=\n-\s*\*\*|\Z)",
                diag_text, re.DOTALL
            )
            if diag_type_m:
                diagrams.append({
                    "id": diag_id.strip(),
                    "brief": diag_brief_m.group(1).strip() if diag_brief_m else "",
                    "type": diag_type_m.group(1).strip(),
                    "description": diag_desc_m.group(1).strip() if diag_desc_m else "",
                })
        if diagrams:
            result["diagrams"] = diagrams

    return result


def parse_methods_md(filepath: Path) -> dict:
    """Parse a Phase 1 methods.md into a dict of method_name → method_data."""
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    methods = {}
    # Split by ## headings (level 2) — each is a method
    method_sections = split_by_headings(content, level=2)

    for method_name, body in method_sections.items():
        method_data = parse_single_method(body)
        if method_data:
            methods[method_name] = method_data

    return methods


# --- Raw docs helpers (Phase 3 unstructured import) ---

def build_class_lookup(base_dir: Path) -> dict:
    """Build a case-insensitive lookup from base JSON files.

    Returns a dict with two sub-dicts:
      {
        "classes": { "array": "Array", "engine": "Engine", ... },
        "methods": { "array": { "clone": "clone", "find": "find", ... }, ... }
      }
    The keys are lowercase slugs (as used in docs.hise.dev URLs).
    The values are canonical PascalCase/camelCase names from the base JSON.
    """
    lookup = {"classes": {}, "methods": {}}
    for json_path in sorted(base_dir.glob("*.json")):
        with open(json_path, "r", encoding="utf-8") as f:
            base = json.load(f)
        class_name = base["className"]
        # Map lowercase slug -> canonical name
        # docs.hise.dev uses "globalcable" for "GlobalCable", etc.
        slug = class_name.lower()
        lookup["classes"][slug] = class_name
        method_map = {}
        for method_name in base.get("methods", {}).keys():
            method_map[method_name.lower()] = method_name
        lookup["methods"][slug] = method_map
    return lookup


def convert_doc_link(url: str, link_text: str, class_lookup: dict) -> tuple:
    """Convert a docs.hise.dev link to a backtick reference + crossReference.

    Args:
        url: The link URL, e.g. "/scripting/scripting-api/array#clone"
        link_text: The display text from the markdown link
        class_lookup: Output of build_class_lookup()

    Returns:
        (replacement_text, cross_ref_or_None)
        replacement_text: backtick-wrapped canonical name, e.g. "`Array.clone()`"
        cross_ref_or_None: "Array.clone" or None if class-only or non-API link
    """
    # Match /scripting/scripting-api/classslug or /scripting/scripting-api/classslug#method
    m = re.match(r"/scripting/scripting-api/([a-z0-9_-]+?)(?:#([a-z0-9_-]+))?$", url, re.IGNORECASE)
    if not m:
        # Non-API link -- strip markup, keep link text
        return (link_text, None)

    class_slug = m.group(1).lower()
    method_slug = m.group(2).lower() if m.group(2) else None

    canonical_class = class_lookup["classes"].get(class_slug)
    if not canonical_class:
        # Unknown class -- keep link text as-is
        return (link_text, None)

    if method_slug:
        method_map = class_lookup["methods"].get(class_slug, {})
        canonical_method = method_map.get(method_slug, method_slug)
        ref = f"{canonical_class}.{canonical_method}"
        return (f"`{ref}()`", ref)
    else:
        # Class-level link, no method
        return (f"`{canonical_class}`", None)


def parse_raw_docs(content: str, class_lookup: dict) -> dict:
    """Parse raw (unstructured) docs content into userDocs + examples + crossReferences.

    Used for Phase 3 files imported from docs.hise.dev that lack structured
    markers like **Signature:**, **Description:**, etc.

    Args:
        content: Raw markdown content
        class_lookup: Output of build_class_lookup()

    Returns:
        {"userDocs": str_or_None, "examples": list, "crossReferences": list}
    """
    cross_refs = []

    # Step 1: Strip image references  ![alt](/path)
    content = re.sub(r"!\[[^\]]*\]\([^)]+\)", "", content)

    # Step 2: Convert doc-site links  [text](/scripting/scripting-api/class#method)
    def _replace_link(m):
        link_text = m.group(1)
        url = m.group(2)
        replacement, xref = convert_doc_link(url, link_text, class_lookup)
        if xref and xref not in cross_refs:
            cross_refs.append(xref)
        return replacement

    content = re.sub(r"\[([^\]]+)\]\(([^)]+)\)", _replace_link, content)

    # Step 3: Strip non-API link remnants that slipped through
    # (already handled by convert_doc_link returning plain text)

    # Step 4: Strip #### Example headings
    content = re.sub(r"^####\s+[Ee]xample.*$", "", content, flags=re.MULTILINE)

    # Step 5: Split into prose and code blocks
    # Find all fenced code blocks with their positions
    code_block_pattern = re.compile(r"```\w*\n(.*?)```", re.DOTALL)
    code_blocks = list(code_block_pattern.finditer(content))

    if not code_blocks:
        # No code -- entire content is userDocs
        prose = content.strip()
        # Clean up multiple blank lines
        prose = re.sub(r"\n{3,}", "\n\n", prose)
        result = {}
        if prose:
            result["userDocs"] = prose
        if cross_refs:
            result["crossReferences"] = cross_refs
        return result

    # Extract prose (everything outside code fences)
    prose_parts = []
    last_end = 0
    for block in code_blocks:
        before = content[last_end:block.start()].strip()
        if before:
            prose_parts.append(before)
        last_end = block.end()
    # Trailing prose after the last code block
    trailing = content[last_end:].strip()
    if trailing:
        prose_parts.append(trailing)

    prose = "\n\n".join(prose_parts)
    # Clean up multiple blank lines
    prose = re.sub(r"\n{3,}", "\n\n", prose)

    # Extract examples
    examples = []
    for block in code_blocks:
        code = block.group(1).strip()
        if code:
            examples.append({
                "title": "Example",
                "code": code,
                "source": "manual",
            })

    result = {}
    if prose:
        result["userDocs"] = prose
    if examples:
        result["examples"] = examples
    if cross_refs:
        result["crossReferences"] = cross_refs
    return result


def parse_method_override_md(filepath: Path, class_lookup: dict = None) -> dict:
    """Parse a Phase 2/3 method override file (single method).

    Supports two formats:
    1. Structured format with **Signature:**, **Description:**, etc.
    2. Raw docs format: prose paragraph(s) followed by ```code``` blocks.
       When class_lookup is provided, prose goes to userDocs (not description)
       and doc-site links are converted to cross-references.
       When class_lookup is None (Phase 2), prose goes to description (legacy).
    """
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    # Strip a leading ## heading if present (method name is inferred
    # from the filename, so the heading is optional).
    content_stripped = re.sub(r"^##\s+\S+.*\n", "", content, count=1)

    result = parse_single_method(content_stripped)
    if result:
        return result

    # Fallback: raw docs format.
    if class_lookup:
        # Phase 3 with class_lookup: use parse_raw_docs for proper
        # userDocs/examples/crossReferences splitting.
        return parse_raw_docs(content, class_lookup)

    # Legacy path (Phase 2, no class_lookup): prose -> description.
    fence_idx = content.find("```")
    if fence_idx == -1:
        # No code blocks -- entire content is description
        desc = content.strip()
        if desc:
            return {"description": desc}
        return {}

    desc = content[:fence_idx].strip()
    examples = parse_examples(content[fence_idx:])

    result = {}
    if desc:
        result["description"] = desc
    if examples:
        result["examples"] = examples
    return result


def parse_single_method(body: str) -> dict:
    """Parse a single method's markdown body into structured data."""
    result = {}

    # Check for disabled method (minimal entry -- skip further parsing)
    disabled_match = re.search(r"\*\*Disabled:\*\*\s*(\S+)", body)
    if disabled_match:
        result["disabled"] = True
        result["disabledReason"] = disabled_match.group(1).strip()
        # Extract the detail text
        detail_match = re.search(
            r"\*\*Disabled Reason:\*\*\s*(.*?)(?=\n\*\*|\n##|\Z)",
            body, re.DOTALL
        )
        if detail_match:
            result["disabledDetail"] = detail_match.group(1).strip()
        return result

    # Extract bold-prefixed fields
    sig_match = re.search(r"\*\*Signature:\*\*\s*`([^`]+)`", body)
    if sig_match:
        result["signature"] = sig_match.group(1)

    rt_match = re.search(r"\*\*Return Type:\*\*\s*`?([^`\n]+)`?", body)
    if rt_match:
        result["returnType"] = rt_match.group(1).strip()

    # callScope (new five-tier system: safe, warning, unsafe, init, unknown)
    # Also supports legacy **Realtime Safe:** for backward compatibility during migration
    cs_match = re.search(r"\*\*Call Scope:\*\*\s*(\S+)", body)
    if not cs_match:
        # Fallback: parse legacy **Realtime Safe:** and map to new tiers
        cs_match = re.search(r"\*\*Realtime Safe:\*\*\s*(\S+)", body)
        if cs_match:
            legacy_val = cs_match.group(1).strip().lower()
            if legacy_val == "true":
                result["callScope"] = "safe"
            elif legacy_val == "false":
                result["callScope"] = "unsafe"
            else:
                result["callScope"] = None
    else:
        val = cs_match.group(1).strip().lower()
        if val in ("safe", "warning", "unsafe", "init"):
            result["callScope"] = val
        elif val == "unknown":
            result["callScope"] = None
        else:
            result["callScope"] = None

    csn_match = re.search(r"\*\*Call Scope Note:\*\*\s*(.+)", body)
    if csn_match:
        note = csn_match.group(1).strip()
        if note and note.lower() not in ("none", "null", "--", "n/a"):
            result["callScopeNote"] = note

    me_match = re.search(r"\*\*Minimal Example:\*\*\s*`([^`]+)`", body)
    if me_match:
        result["minimalExample"] = me_match.group(1)

    # Description
    desc_match = re.search(
        r"\*\*Description:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if desc_match:
        result["description"] = desc_match.group(1).strip()

    # Parameters table
    params_match = re.search(
        r"\*\*Parameters:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if params_match:
        params_text = params_match.group(1)
        params = parse_parameter_table(params_text)
        if params:
            result["parameters"] = params

    # Value Descriptions table
    vd_match = re.search(
        r"\*\*Value Descriptions:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if vd_match:
        vd_rows = parse_markdown_table(vd_match.group(1))
        if vd_rows:
            result["valueDescriptions"] = [
                {"value": r.get("Value", ""),
                 "description": r.get("Description", "")}
                for r in vd_rows
            ]

    # Callback Properties table
    cp_match = re.search(
        r"\*\*Callback Properties:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if cp_match:
        cp_rows = parse_markdown_table(cp_match.group(1))
        if cp_rows:
            result["callbackProperties"] = [
                {"property": r.get("Property", ""),
                 "type": r.get("Type", ""),
                 "description": r.get("Description", "")}
                for r in cp_rows
            ]

    # Callback Signature: paramName(arg1: type1, arg2: type2)
    cb_sig_match = re.search(
        r"\*\*Callback Signature:\*\*\s*(\w+)\(([^)]*)\)",
        body
    )
    if cb_sig_match:
        param_name = cb_sig_match.group(1)
        args_str = cb_sig_match.group(2).strip()
        cb_params = []
        if args_str:
            for arg in args_str.split(","):
                arg = arg.strip()
                if ":" in arg:
                    aname, atype = arg.split(":", 1)
                    cb_params.append({
                        "name": aname.strip(),
                        "type": atype.strip()
                    })
                else:
                    cb_params.append({"name": arg, "type": "var"})
        result["callbackSignature"] = {
            "parameterName": param_name,
            "parameters": cb_params,
        }

    # Pitfalls
    pitfalls_match = re.search(
        r"\*\*Pitfalls:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if pitfalls_match:
        pitfalls_text = pitfalls_match.group(1)
        pitfalls = parse_bullet_list(pitfalls_text)
        if pitfalls:
            result["pitfalls"] = pitfalls

    # Cross References
    xref_match = re.search(
        r"\*\*Cross References:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if xref_match:
        xref_text = xref_match.group(1)
        xrefs = []
        for line in xref_text.strip().splitlines():
            line = line.strip().lstrip("-").strip()
            # Remove backticks
            line = line.strip("`")
            if line:
                xrefs.append(line)
        if xrefs:
            result["crossReferences"] = xrefs

    # Diagram (method-owned, single)
    diag_match = re.search(
        r"\*\*Diagram:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if diag_match:
        diag_text = diag_match.group(1)
        diag_type_m = re.search(r"-\s*\*\*Type:\*\*\s*(\S+)", diag_text)
        diag_brief_m = re.search(
            r"-\s*\*\*Brief:\*\*\s*(.*?)(?=\n-\s*\*\*|\Z)",
            diag_text, re.DOTALL
        )
        diag_desc_m = re.search(
            r"-\s*\*\*Description:\*\*\s*(.*?)(?=\n-\s*\*\*|\Z)",
            diag_text, re.DOTALL
        )
        if diag_type_m:
            result["diagram"] = {
                "type": diag_type_m.group(1).strip(),
                "brief": diag_brief_m.group(1).strip() if diag_brief_m else "",
                "description": diag_desc_m.group(1).strip() if diag_desc_m else "",
            }

    # DiagramRef (reference to class-level diagram, mutually exclusive with Diagram)
    diag_ref_match = re.search(
        r"\*\*DiagramRef:\*\*\s*(\S+)",
        body
    )
    if diag_ref_match and "diagram" not in result:
        result["diagramRef"] = diag_ref_match.group(1).strip()

    # Example(s)
    example_match = re.search(
        r"\*\*Example(?:s)?:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if example_match:
        examples = parse_examples(example_match.group(1))
        if examples:
            result["examples"] = examples

    return result


# --- Markdown parsing helpers ---

def split_by_headings(content: str, level: int = 2) -> dict:
    """Split markdown content by headings of a given level.
    Returns dict of heading_text → body_text.
    """
    prefix = "#" * level
    pattern = rf"^{prefix}\s+(.+)$"
    sections = {}
    current_heading = None
    current_lines = []

    for line in content.splitlines():
        match = re.match(pattern, line)
        if match:
            if current_heading is not None:
                sections[current_heading] = "\n".join(current_lines)
            current_heading = match.group(1).strip()
            current_lines = []
        elif current_heading is not None:
            current_lines.append(line)

    if current_heading is not None:
        sections[current_heading] = "\n".join(current_lines)

    return sections


def extract_code_block(text: str) -> str:
    """Extract the content of the first fenced code block."""
    match = re.search(r"```\w*\n(.*?)```", text, re.DOTALL)
    if match:
        return match.group(1).strip()
    # Fall back to the raw text
    return text.strip()


def parse_markdown_table(text: str) -> list:
    """Parse a pipe-delimited markdown table into a list of dicts.
    First row is headers, second row is separator, rest are data.
    """
    lines = [l.strip() for l in text.strip().splitlines() if l.strip()]
    # Find table lines (contain |)
    table_lines = [l for l in lines if "|" in l]
    if len(table_lines) < 3:
        return []

    # Parse header
    headers = [h.strip() for h in table_lines[0].split("|") if h.strip()]

    # Skip separator (table_lines[1])
    rows = []
    for line in table_lines[2:]:
        cells = [c.strip() for c in line.split("|") if c.strip()]
        if len(cells) >= len(headers):
            row = {}
            for i, header in enumerate(headers):
                row[header] = cells[i] if i < len(cells) else ""
            rows.append(row)

    return rows


def parse_parameter_table(text: str) -> list:
    """Parse a parameter table from method markdown."""
    rows = parse_markdown_table(text)
    params = []
    for row in rows:
        param = {
            "name": row.get("Name", ""),
            "type": row.get("Type", ""),
            "forcedType": row.get("Forced", "").lower() in ("yes", "true"),
            "description": row.get("Description", ""),
        }
        constraints = row.get("Constraints", "")
        if constraints and constraints != "—":
            param["constraints"] = constraints
        params.append(param)
    return params


def parse_bullet_list(text: str) -> list:
    """Parse a markdown bullet list into a list of strings."""
    items = []
    for line in text.strip().splitlines():
        line = line.strip()
        if line.startswith("- "):
            items.append(line[2:].strip())
        elif line.startswith("* "):
            items.append(line[2:].strip())
    return items


def parse_examples(text: str) -> list:
    """Parse example sections from method markdown."""
    examples = []

    # Find all code blocks, optionally preceded by a title comment
    blocks = re.findall(
        r"(?:(?://\s*(.+)\n)|(?:###\s*(.+)\n))?```\w*\n(.*?)```",
        text, re.DOTALL
    )

    if blocks:
        for title_comment, title_heading, code in blocks:
            title = (title_heading or title_comment or "").strip()
            examples.append({
                "title": title or "Example",
                "code": code.strip(),
            })
    else:
        # Single code block without fence
        code = text.strip()
        if code:
            examples.append({
                "title": "Example",
                "code": code,
            })

    return examples


# --- Merge logic ---

def build_class_description(base_desc: str, readme_data: dict, source_tag: str) -> dict:
    """Build the class description object from base + readme data."""
    desc = {
        "brief": readme_data.get("brief"),
        "purpose": readme_data.get("purpose"),
        "details": readme_data.get("details"),
        "obtainedVia": readme_data.get("obtainedVia"),
        "minimalObjectToken": readme_data.get("minimalObjectToken"),
        "codeExample": readme_data.get("codeExample"),
        "alternatives": readme_data.get("alternatives"),
        "relatedPreprocessors": readme_data.get("relatedPreprocessors", []),
        "userGuidePage": None,
        "diagrams": readme_data.get("diagrams", []),
    }

    # If no enrichment data, use the base description for brief/purpose
    if desc["brief"] is None and base_desc:
        desc["brief"] = base_desc
    if desc["purpose"] is None and base_desc:
        desc["purpose"] = base_desc

    return desc


def build_constants(readme_data: dict, source_tag: str) -> dict:
    """Build constants dict from parsed readme table rows."""
    constants = {}
    for row in readme_data.get("constants", []):
        name = row.get("Name", "")
        if not name:
            continue
        value = row.get("Value", "")
        # Try to parse numeric values
        try:
            value = int(value)
        except (ValueError, TypeError):
            try:
                value = float(value)
            except (ValueError, TypeError):
                pass

        constants[name] = {
            "value": value,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "group": row.get("Group", None) or None,
            "source": source_tag,
        }
    return constants


def build_dynamic_constants(readme_data: dict, source_tag: str) -> dict:
    """Build dynamic constants dict from parsed readme table rows."""
    dyn_constants = {}
    for row in readme_data.get("dynamicConstants", []):
        name = row.get("Name", "")
        if not name:
            continue
        dyn_constants[name] = {
            "value": None,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "source": source_tag,
        }
    return dyn_constants


def build_common_mistakes(readme_data: dict, source_tag: str) -> list:
    """Build common mistakes list from parsed readme table rows."""
    mistakes = []
    for row in readme_data.get("commonMistakes", []):
        mistakes.append({
            "wrong": row.get("Wrong", ""),
            "right": row.get("Right", ""),
            "explanation": row.get("Explanation", ""),
            "source": source_tag,
        })
    return mistakes


def build_method_entry(base_method: dict, enriched: dict, source_tag: str) -> dict:
    """Build a full method entry by merging base data with enrichment."""
    # If the method is disabled, return a minimal entry
    if enriched.get("disabled"):
        entry = {
            "signature": base_method.get("signature", ""),
            "returnType": base_method.get("returnType", ""),
            "description": base_method.get("description", ""),
            "parameters": base_method.get("parameters", []),
            "disabled": True,
            "disabledReason": enriched.get("disabledReason", ""),
            "disabledDetail": enriched.get("disabledDetail", ""),
        }
        return entry

    entry = {
        "signature": enriched.get("signature", base_method.get("signature", "")),
        "returnType": enriched.get("returnType", base_method.get("returnType", "")),
        "description": enriched.get("description", base_method.get("description", "")),
        "parameters": [],
        "callScope": enriched.get("callScope"),
        "callScopeNote": enriched.get("callScopeNote"),
        "minimalExample": enriched.get("minimalExample", ""),
        "crossReferences": enriched.get("crossReferences", []),
        "pitfalls": [],
        "examples": [],
    }

    # Structured value metadata (pass through from enrichment)
    if enriched.get("valueDescriptions"):
        entry["valueDescriptions"] = enriched["valueDescriptions"]
    if enriched.get("callbackProperties"):
        entry["callbackProperties"] = enriched["callbackProperties"]
    if enriched.get("callbackSignature"):
        entry["callbackSignature"] = enriched["callbackSignature"]
    if enriched.get("diagram"):
        entry["diagram"] = enriched["diagram"]
    elif enriched.get("diagramRef"):
        entry["diagramRef"] = enriched["diagramRef"]

    # Parameters: prefer enriched (has forcedType info), fall back to base
    if enriched.get("parameters"):
        entry["parameters"] = enriched["parameters"]
    else:
        # Convert base params (no forcedType info)
        for p in base_method.get("parameters", []):
            entry["parameters"].append({
                "name": p["name"],
                "type": p["type"],
                "forcedType": False,
                "description": p.get("description", ""),
            })

    # Pitfalls: tagged list items
    for pitfall_text in enriched.get("pitfalls", []):
        if isinstance(pitfall_text, dict):
            entry["pitfalls"].append(pitfall_text)
        else:
            entry["pitfalls"].append({
                "description": pitfall_text,
                "source": source_tag,
            })

    # Examples
    for ex in enriched.get("examples", []):
        if isinstance(ex, dict):
            if "source" not in ex:
                ex["source"] = source_tag
            entry["examples"].append(ex)
        else:
            entry["examples"].append({
                "title": "Example",
                "code": str(ex),
                "context": "",
                "source": source_tag,
            })

    return entry


def merge_method_entries(existing: dict, override: dict, source_tag: str) -> dict:
    """Merge an override method entry into an existing one.
    Last-writer-wins for most fields; union merge for pitfalls/crossRefs.
    """
    # If override marks method as disabled, propagate that
    if override.get("disabled"):
        existing["disabled"] = True
        existing["disabledReason"] = override.get("disabledReason", "")
        existing["disabledDetail"] = override.get("disabledDetail", "")
        return existing

    # Last-writer-wins fields
    if override.get("signature"):
        existing["signature"] = override["signature"]
    if override.get("returnType"):
        existing["returnType"] = override["returnType"]
    if override.get("description"):
        existing["description"] = override["description"]
    if override.get("parameters"):
        existing["parameters"] = override["parameters"]
    if "callScope" in override and override["callScope"] is not None:
        existing["callScope"] = override["callScope"]
    if override.get("callScopeNote"):
        existing["callScopeNote"] = override["callScopeNote"]
    if override.get("minimalExample"):
        existing["minimalExample"] = override["minimalExample"]
    if override.get("callbackSignature"):
        existing["callbackSignature"] = override["callbackSignature"]

    # Examples: last-writer-wins (entire array replaced)
    if override.get("examples"):
        existing["examples"] = []
        for ex in override["examples"]:
            if isinstance(ex, dict):
                if "source" not in ex:
                    ex["source"] = source_tag
                existing["examples"].append(ex)
            else:
                existing["examples"].append({
                    "title": "Example",
                    "code": str(ex),
                    "context": "",
                    "source": source_tag,
                })

    # Union merge: pitfalls
    if override.get("pitfalls"):
        for pitfall in override["pitfalls"]:
            if isinstance(pitfall, dict):
                existing.setdefault("pitfalls", []).append(pitfall)
            else:
                existing.setdefault("pitfalls", []).append({
                    "description": pitfall,
                    "source": source_tag,
                })

    # Union merge: crossReferences (deduplicated)
    if override.get("crossReferences"):
        existing_refs = set(existing.get("crossReferences", []))
        for ref in override["crossReferences"]:
            existing_refs.add(ref)
        existing["crossReferences"] = sorted(existing_refs)

    # Last-writer-wins: structured value metadata
    if override.get("valueDescriptions"):
        existing["valueDescriptions"] = override["valueDescriptions"]
    if override.get("callbackProperties"):
        existing["callbackProperties"] = override["callbackProperties"]

    # Last-writer-wins: diagram / diagramRef (mutually exclusive)
    if override.get("diagram"):
        existing["diagram"] = override["diagram"]
        existing.pop("diagramRef", None)
    elif override.get("diagramRef"):
        existing["diagramRef"] = override["diagramRef"]
        existing.pop("diagram", None)

    # Last-writer-wins: userDocs from raw docs (Phase 3)
    if override.get("userDocs"):
        existing["userDocs"] = override["userDocs"]
        existing["userDocOverride"] = True  # treat Phase 3 as manual-grade

    return existing


def _load_phase4_prose(filepath: Path, strip_heading: bool = False) -> str:
    """Load a Phase 4 userDocs file as a flat prose string.

    Strips HTML comments (e.g. diagram triage annotations) and, if
    strip_heading is True, removes a leading '# ClassName' line
    (used for class-level Readme.md files).
    """
    if not filepath.is_file():
        return ""
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read().strip()
    # Remove HTML comments (internal pipeline annotations like diagram triage)
    text = re.sub(r"<!--.*?-->", "", text, flags=re.DOTALL).strip()
    if strip_heading and text.startswith("#"):
        # Remove the first line (heading) and strip leading whitespace
        lines = text.split("\n", 1)
        text = lines[1].strip() if len(lines) > 1 else ""
    return text


def run_merge():
    """Merge all phases into output/api_reference.json."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    output = {
        "version": "1.0",
        "generated": datetime.now(timezone.utc).isoformat(),
        "classes": {},
    }

    base_files = sorted(BASE_DIR.glob("*.json"))
    if not base_files:
        print("ERROR: No base JSON files found.")
        sys.exit(1)

    # Build class lookup for raw docs link conversion (Phase 3)
    class_lookup = build_class_lookup(BASE_DIR)

    for json_path in base_files:
        with open(json_path, "r", encoding="utf-8") as f:
            base = json.load(f)

        class_name = base["className"]
        category = base.get("category", CATEGORY_MAP.get(class_name, "object"))

        # --- Phase 1 data ---
        p1_readme = {}
        p1_methods = {}
        p1_class_dir = PHASE1_DIR / class_name
        if p1_class_dir.is_dir():
            p1_readme = parse_readme_md(p1_class_dir / "Readme.md")
            p1_methods = parse_methods_md(p1_class_dir / "methods.md")

        # Case-insensitive method name lookup: lowercase -> canonical name
        method_name_map = {m.lower(): m for m in base.get("methods", {}).keys()}
        for m in p1_methods:
            method_name_map.setdefault(m.lower(), m)

        # --- Phase 2 data ---
        p2_methods = {}
        p2_class_dir = PHASE2_DIR / class_name
        if p2_class_dir.is_dir():
            for md_file in p2_class_dir.glob("*.md"):
                raw_name = md_file.stem
                method_name = method_name_map.get(raw_name.lower(), raw_name)
                p2_methods[method_name] = parse_method_override_md(md_file)

        # --- Phase 3 data ---
        p3_readme = {}
        p3_methods = {}
        p3_class_dir = PHASE3_DIR / class_name
        if p3_class_dir.is_dir():
            readme_path = p3_class_dir / "Readme.md"
            if readme_path.is_file():
                p3_readme = parse_readme_md(readme_path)
            for md_file in p3_class_dir.glob("*.md"):
                if md_file.name.lower() != "readme.md":
                    raw_name = md_file.stem
                    method_name = method_name_map.get(raw_name.lower(), raw_name)
                    p3_methods[method_name] = parse_method_override_md(md_file, class_lookup)

        # --- Phase 4 data (userDocs) ---
        # manual/ wins over auto/. Files are flat prose (parsed by
        # _load_phase4_prose which strips an optional # heading).
        p4_class_userdocs = None
        p4_class_override = False
        p4_method_userdocs = {}  # method_name -> (prose, is_override)

        # Class-level Readme.md
        manual_readme = PHASE4_MANUAL_DIR / class_name / "Readme.md"
        auto_readme = PHASE4_AUTO_DIR / class_name / "Readme.md"
        if manual_readme.is_file():
            p4_class_userdocs = _load_phase4_prose(manual_readme, strip_heading=True)
            p4_class_override = True
        elif auto_readme.is_file():
            p4_class_userdocs = _load_phase4_prose(auto_readme, strip_heading=True)

        # Method-level files
        for phase4_dir, is_override in ((PHASE4_MANUAL_DIR, True), (PHASE4_AUTO_DIR, False)):
            method_dir = phase4_dir / class_name
            if not method_dir.is_dir():
                continue
            for md_file in method_dir.glob("*.md"):
                if md_file.name.lower() == "readme.md":
                    continue
                raw_name = md_file.stem
                canonical = method_name_map.get(raw_name.lower(), raw_name)
                # manual/ wins: if already set by manual pass, skip auto
                if canonical in p4_method_userdocs and not is_override:
                    continue
                prose = _load_phase4_prose(md_file, strip_heading=False)
                if prose:
                    p4_method_userdocs[canonical] = (prose, is_override)

        # --- Build class description ---
        # Start with Phase 1, override with Phase 3 (last-writer-wins)
        desc = build_class_description(base.get("description", ""), p1_readme, "auto")

        # Phase 3 overrides (last-writer-wins)
        for field in ("brief", "purpose", "details", "obtainedVia",
                       "minimalObjectToken", "codeExample", "alternatives",
                       "relatedPreprocessors"):
            if field in p3_readme:
                desc[field] = p3_readme[field]

        # Phase 3 diagrams override (merge by id, last-writer-wins per id)
        if p3_readme.get("diagrams"):
            existing_by_id = {d["id"]: d for d in desc.get("diagrams", [])}
            for diag in p3_readme["diagrams"]:
                existing_by_id[diag["id"]] = diag
            desc["diagrams"] = list(existing_by_id.values())

        # Phase 4: userDocs for class level
        desc["userDocs"] = p4_class_userdocs
        desc["userDocOverride"] = p4_class_override if p4_class_userdocs else False

        # --- Constants ---
        constants = build_constants(p1_readme, "auto")
        p3_constants = build_constants(p3_readme, "manual")
        constants.update(p3_constants)  # Last-writer-wins per constant

        # --- Dynamic Constants ---
        dyn_constants = build_dynamic_constants(p1_readme, "auto")
        p3_dyn = build_dynamic_constants(p3_readme, "manual")
        dyn_constants.update(p3_dyn)

        # --- Common Mistakes (union merge) ---
        common_mistakes = build_common_mistakes(p1_readme, "auto")
        common_mistakes.extend(build_common_mistakes(p3_readme, "manual"))

        # --- Methods ---
        methods_output = {}
        all_method_names = set(base.get("methods", {}).keys())
        all_method_names.update(p1_methods.keys())
        all_method_names.update(p2_methods.keys())
        all_method_names.update(p3_methods.keys())

        for method_name in sorted(all_method_names):
            base_method = base.get("methods", {}).get(method_name, {})
            p1_method = p1_methods.get(method_name, {})
            p2_method = p2_methods.get(method_name, {})
            p3_method = p3_methods.get(method_name, {})

            # Start with base + Phase 1
            entry = build_method_entry(base_method, p1_method, "auto")

            # Apply Phase 2 overrides
            if p2_method:
                entry = merge_method_entries(entry, p2_method, "project")

            # Apply Phase 3 overrides
            if p3_method:
                entry = merge_method_entries(entry, p3_method, "manual")

            # Phase 4: userDocs for method level
            # Priority: Phase 4 manual > Phase 3 raw docs > Phase 4 auto
            if method_name in p4_method_userdocs:
                prose, is_override = p4_method_userdocs[method_name]
                if is_override:
                    # Phase 4 manual wins over everything
                    entry["userDocs"] = prose
                    entry["userDocOverride"] = True
                elif not entry.get("userDocs"):
                    # Phase 4 auto only if no Phase 3 raw docs userDocs
                    entry["userDocs"] = prose
                    entry["userDocOverride"] = False
            else:
                # No Phase 4 data -- keep Phase 3 userDocs if present
                if not entry.get("userDocs"):
                    entry["userDocs"] = None
                    entry["userDocOverride"] = False

            methods_output[method_name] = entry

        # --- Resolve minimalObjectToken and substitute {obj} ---
        # Priority: Readme > MINIMAL_OBJECT_TOKEN dict > empty string
        token = desc.get("minimalObjectToken")
        if token is None:
            token = MINIMAL_OBJECT_TOKEN.get(class_name, "")
        desc["minimalObjectToken"] = token

        for m in methods_output.values():
            me = m.get("minimalExample", "")
            if me and token:
                m["minimalExample"] = me.replace("{obj}", token)

        # --- Assemble class output ---
        output["classes"][class_name] = {
            "description": desc,
            "category": category,
            "constants": constants if constants else {},
            "dynamicConstants": dyn_constants if dyn_constants else {},
            "commonMistakes": common_mistakes if common_mistakes else [],
            "methods": methods_output,
        }

    # Write output
    output_path = OUTPUT_DIR / "api_reference.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    class_count = len(output["classes"])
    method_count = sum(
        len(c["methods"]) for c in output["classes"].values()
    )
    print(f"Merge complete:")
    print(f"  Classes: {class_count}")
    print(f"  Total methods: {method_count}")
    print(f"  Output: {output_path}")


# ===================================================================
# Preview
# ===================================================================

PREVIEW_DIR = OUTPUT_DIR / "preview"


def md_inline(text: str) -> str:
    """HTML-escape text, then convert inline markdown to HTML tags.

    Handles: `code`, **bold**, *italic*, ![alt](src) images.
    """
    text = html_escape(text)
    text = re.sub(r"`([^`]+)`", r"<code>\1</code>", text)
    # Bold (**text**) -- must come before italic
    text = re.sub(r"\*\*([^*]+)\*\*", r"<strong>\1</strong>", text)
    # Italic (*text*) -- single asterisk, not inside bold
    text = re.sub(r"\*([^*]+)\*", r"<em>\1</em>", text)
    # Inline images ![alt](src) -- SVG diagrams get a diagram-{id} anchor
    def _img_replace(m):
        alt, src = m.group(1), m.group(2)
        img_tag = f'<img src="images/{src}" alt="{alt}" style="max-width:100%;">'
        # SVG diagrams: extract id from {type}_{id}.svg pattern
        svg_match = re.match(r"[a-z]+_(.+)\.svg$", src)
        if svg_match:
            diagram_id = svg_match.group(1)
            return f'<div id="diagram-{diagram_id}" style="margin:16px 0;">{img_tag}</div>'
        return img_tag
    text = re.sub(r"!\[([^\]]*)\]\(([^)]+)\)", _img_replace, text)
    # Inline links [text](url)
    text = re.sub(r"\[([^\]]+)\]\(([^)]+)\)", r'<a href="\2">\1</a>', text)
    return text


def _md_table_to_html(block: str) -> str:
    """Convert a markdown pipe table block to an HTML <table>.

    Returns empty string if the block is not a valid markdown table.
    """
    lines = [l.strip() for l in block.strip().splitlines() if l.strip()]
    if len(lines) < 2:
        return ""
    # All lines must start with '|'
    if not all(l.startswith("|") for l in lines):
        return ""
    # Second line must be the separator (contains only |, -, :, spaces)
    if not re.match(r"^[\s|:\-]+$", lines[1]):
        return ""

    def split_row(line: str) -> list:
        cells = line.strip("|").split("|")
        return [c.strip() for c in cells]

    headers = split_row(lines[0])
    html = '<table class="md-table">\n<thead><tr>'
    for h in headers:
        html += f"<th>{md_inline(h)}</th>"
    html += "</tr></thead>\n<tbody>\n"
    for row_line in lines[2:]:
        cells = split_row(row_line)
        html += "<tr>"
        for cell in cells:
            html += f"<td>{md_inline(cell)}</td>"
        html += "</tr>\n"
    html += "</tbody></table>\n"
    return html


def md_block(block: str) -> str:
    """Render a markdown block as HTML -- table, heading, list, code fence, or paragraph."""
    block = block.strip()
    if not block:
        return ""

    # Code fence (```...```)
    if block.startswith("```"):
        lines = block.split("\n")
        lang_match = re.match(r"^```(\w+)?", lines[0])
        lang = lang_match.group(1) if lang_match and lang_match.group(1) else "javascript"
        # Find closing fence
        code_lines = []
        for line in lines[1:]:
            if line.strip() == "```":
                break
            code_lines.append(line)
        code_text = html_escape("\n".join(code_lines))
        return f'<pre><code class="language-{lang}">{code_text}</code></pre>\n'

    # Table
    table_html = _md_table_to_html(block)
    if table_html:
        return table_html

    lines = block.split("\n")

    # Heading (###, ##, #)
    if lines[0].startswith("#"):
        heading_match = re.match(r"^(#{1,6})\s+(.*)", lines[0])
        if heading_match:
            level = len(heading_match.group(1))
            text = heading_match.group(2)
            html = f"<h{level}>{md_inline(text)}</h{level}>\n"
            # If there are more lines after the heading, render them too
            rest = "\n".join(lines[1:]).strip()
            if rest:
                html += md_block(rest)
            return html

    # Bullet list (lines starting with "- ")
    if all(l.startswith("- ") or l.startswith("  ") or l == "" for l in lines) and any(l.startswith("- ") for l in lines):
        html = "<ul>\n"
        for line in lines:
            line = line.strip()
            if line.startswith("- "):
                html += f"<li>{md_inline(line[2:])}</li>\n"
            elif line and not line.startswith("- "):
                # Continuation line -- append to previous li (simplified)
                html += f"  {md_inline(line)}\n"
        html += "</ul>\n"
        return html

    # Default: paragraph
    return f"<p>{md_inline(block)}</p>\n"


# ---------------------------------------------------------------------------
# Display-type mapping for HTML preview (HISEScript-idiomatic types)
# ---------------------------------------------------------------------------

# Exact type replacements
_DISPLAY_TYPE_MAP = {
    "NotUndefined": "var",
    "undefined": None,       # None = omit when used as return type
    "void": None,
    "int64": "int",
    "Integer": "int",
    "float": "double",
    "Double": "double",
    "Number": "double",
    "DynamicObject *": "Object",
    "MainController *": "var",
    "NodeBase::Holder *": "var",
    "JSON": "var",
    "ScriptObject": "Object",
}


def display_type(raw_type: str):
    """Map a raw C++ type to a HISEScript-idiomatic display type.

    Returns None for void-like types (caller should omit the return type).
    Returns the cleaned string for everything else.
    """
    t = raw_type.strip()

    # Exact match first
    if t in _DISPLAY_TYPE_MAP:
        return _DISPLAY_TYPE_MAP[t]

    # ScriptingObjects::X * -> X
    if t.startswith("ScriptingObjects::"):
        t = t.replace("ScriptingObjects::", "")
        return t.rstrip(" *")

    # Other pointer types: strip trailing " *"
    if t.endswith(" *"):
        return t[:-2]

    # ScriptingSamplerSound *, ScriptingSynth * (no namespace prefix)
    if t.endswith("*"):
        return t.rstrip("*").rstrip()

    return t


def format_signature(class_name: str, method_name: str, m: dict) -> str:
    """Build a HISEScript-idiomatic signature for HTML display.

    Format: [ReturnType ]ClassName.methodName(Type param, ...)
    Return type is omitted when void/undefined.
    """
    # Return type
    ret = display_type(m.get("returnType", "undefined"))

    # Parameters
    param_strs = []
    for p in m.get("parameters", []):
        pt = display_type(p.get("type", "var"))
        if pt is None:
            pt = "var"
        param_strs.append(f"{pt} {p.get('name', '')}")

    sig = f"{class_name}.{method_name}({', '.join(param_strs)})"
    if ret is not None:
        sig = f"{ret} {sig}"
    return sig


def generate_class_html(class_name: str, c: dict, mode: str = "review") -> str:
    """Generate a full HTML preview page for one class.

    mode="review" -- shows raw C++ analysis (brief/purpose/details + description)
    mode="web"    -- shows userDocs content with auto/manual badges
    """
    is_web = mode == "web"
    desc = c.get("description", {})
    methods = c.get("methods", {})

    # --- Collect sidebar section IDs ---
    sidebar_sections = []
    if is_web:
        if desc.get("userDocs"):
            sidebar_sections.append(("overview", "Overview"))
    else:
        if desc.get("purpose"):
            sidebar_sections.append(("overview", "Overview"))
        if desc.get("details"):
            sidebar_sections.append(("details", "Details"))
    if desc.get("codeExample"):
        sidebar_sections.append(("usage-example", "Usage Example"))
    if c.get("commonMistakes"):
        sidebar_sections.append(("common-mistakes", "Common Mistakes"))
    if not is_web and desc.get("relatedPreprocessors"):
        sidebar_sections.append(("preprocessors", "Preprocessors"))

    # --- Sidebar HTML ---
    sidebar = f'<div class="sidebar">\n'
    sidebar += f'<div class="sidebar-title">{class_name}</div>\n'
    if is_web:
        sidebar += '<div class="sidebar-mode mode-web">userDocs</div>\n'
    else:
        sidebar += '<div class="sidebar-mode mode-review">review</div>\n'
    for sid, label in sidebar_sections:
        sidebar += f'<a class="sidebar-link" href="#{sid}">{label}</a>\n'
    if methods:
        sidebar += '<div class="sidebar-divider">Methods</div>\n'
        for name, m in methods.items():
            # Skip disabled methods in web mode sidebar
            if is_web and m.get("disabled"):
                continue
            sidebar += f'<a class="sidebar-link sidebar-method" href="#{name}">{name}</a>\n'
    sidebar += '</div>\n'

    # --- Build all section IDs for IntersectionObserver ---
    active_methods = [n for n, m in methods.items() if not (is_web and m.get("disabled"))]
    all_ids = [sid for sid, _ in sidebar_sections] + active_methods
    ids_js = ", ".join(f'"{i}"' for i in all_ids)

    # --- Main content ---
    main = '<div class="main">\n'

    # Header
    mode_label = "userDocs" if is_web else "review"
    main += f'<h1>{class_name} <span class="category">{md_inline(c.get("category", ""))}</span></h1>\n'
    if desc.get("brief"):
        main += f'<p class="brief">{md_inline(desc["brief"])}</p>\n'
    if not is_web and desc.get("obtainedVia"):
        main += f'<p><strong>Obtained via:</strong> {md_inline(desc["obtainedVia"])}</p>\n'

    # Class-level prose
    if is_web:
        if desc.get("userDocs"):
            main += '<h2 id="overview">Overview</h2>\n'
            for para in desc["userDocs"].split("\n\n"):
                para = para.strip()
                if para:
                    main += md_block(para)
    else:
        # Review mode: show purpose + details
        if desc.get("purpose"):
            main += '<h2 id="overview">Overview</h2>\n'
            main += f'<p>{md_inline(desc["purpose"])}</p>\n'
        if desc.get("details"):
            main += '<h2 id="details">Details</h2>\n'
            for para in desc["details"].split("\n\n"):
                para = para.strip()
                if para:
                    main += md_block(para)

    # Code example (both modes)
    if desc.get("codeExample"):
        main += '<h2 id="usage-example">Usage Example</h2>\n'
        main += f'<pre><code class="language-javascript">{html_escape(desc["codeExample"])}</code></pre>\n'

    # Common mistakes (both modes)
    if c.get("commonMistakes"):
        main += '<h2 id="common-mistakes">Common Mistakes</h2>\n'
        for m in c["commonMistakes"]:
            main += (
                '<div class="mistake">'
                f'<strong>Wrong:</strong> {md_inline(m["wrong"])}<br>'
                f'<strong>Right:</strong> {md_inline(m["right"])}<br>'
                f'<em>{md_inline(m["explanation"])}</em></div>\n'
            )

    # Related preprocessors (review mode only)
    if not is_web and desc.get("relatedPreprocessors"):
        main += '<h2 id="preprocessors">Related Preprocessors</h2>\n'
        main += "<p>" + ", ".join(
            f"<code>{p}</code>" for p in desc["relatedPreprocessors"]
        ) + "</p>\n"

    # Methods
    if methods:
        main += '<h2 id="methods-heading">Methods</h2>\n'

        for name, m in methods.items():
            # Disabled methods: skip in web mode, annotate in review mode
            if m.get("disabled"):
                if is_web:
                    continue
                # Review mode: show a dimmed annotation
                main += f'<div class="method-card method-disabled" id="{name}">\n'
                reason = m.get("disabledReason", "")
                detail = m.get("disabledDetail", "")
                main += f'<h3 class="signature disabled">{html_escape(name)}</h3>\n'
                main += f'<p class="disabled-label">Disabled: <strong>{html_escape(reason)}</strong></p>\n'
                if detail:
                    main += f'<p class="disabled-detail">{md_inline(detail)}</p>\n'
                main += "</div>\n"
                continue

            sig = format_signature(class_name, name, m)

            # Call scope LED
            call_scope = m.get("callScope")
            scope_class = {
                "safe": "scope-safe",
                "warning": "scope-warning",
                "unsafe": "scope-unsafe",
                "init": "scope-init",
            }.get(call_scope, "scope-unknown")
            scope_label = call_scope or "unknown"
            scope_note = m.get("callScopeNote", "")
            scope_tip = f"{scope_label}: {scope_note}" if scope_note else scope_label
            scope_led = f' <span class="callscope-led {scope_class}" title="{html_escape(scope_tip)}"></span>'

            main += f'<div class="method-card" id="{name}">\n'
            main += f'<h3 class="signature">{html_escape(sig)}{scope_led}</h3>\n'

            # Minimal example (right after signature, both modes)
            if m.get("minimalExample"):
                main += f'<p class="minimal-example"><code>{html_escape(m["minimalExample"])}</code></p>\n'

            # Params (right after signature, both modes)
            if m.get("parameters"):
                main += "<table><tr><th>Parameter</th><th>Type</th><th>Description</th></tr>\n"
                for p in m["parameters"]:
                    pt = display_type(p.get("type", "var")) or "var"
                    main += (
                        f'<tr><td><code>{html_escape(p.get("name", ""))}</code></td>'
                        f'<td><code>{html_escape(pt)}</code></td>'
                        f'<td>{md_inline(p.get("description", ""))}</td></tr>\n'
                    )
                main += "</table>\n"

            # Method description: web mode uses userDocs, review uses description
            if is_web and m.get("userDocs"):
                ud_text = m["userDocs"]
                # Render multi-block userDocs (may contain tables)
                for para in ud_text.split("\n\n"):
                    para = para.strip()
                    if para:
                        main += md_block(para)
            else:
                main += f'<p>{md_inline(m.get("description", ""))}</p>\n'

            # Value Descriptions (review mode only -- userDocs covers this in web mode)
            if not is_web and m.get("valueDescriptions"):
                main += "<table><tr><th>Value</th><th>Description</th></tr>\n"
                for vd in m["valueDescriptions"]:
                    main += (
                        f'<tr><td><code>{html_escape(vd.get("value", ""))}</code></td>'
                        f'<td>{md_inline(vd.get("description", ""))}</td></tr>\n'
                    )
                main += "</table>\n"

            # Callback Properties (review mode only -- userDocs covers this in web mode)
            if not is_web and m.get("callbackProperties"):
                main += "<table><tr><th>Property</th><th>Type</th><th>Description</th></tr>\n"
                for cp in m["callbackProperties"]:
                    main += (
                        f'<tr><td><code>{html_escape(cp.get("property", ""))}</code></td>'
                        f'<td><code>{html_escape(cp.get("type", ""))}</code></td>'
                        f'<td>{md_inline(cp.get("description", ""))}</td></tr>\n'
                    )
                main += "</table>\n"

            # Pitfalls (both modes)
            for p in m.get("pitfalls", []):
                main += f'<div class="pitfall">{md_inline(p.get("description", ""))}</div>\n'

            # Examples (both modes)
            for ex in m.get("examples", []):
                main += f'<pre><code class="language-javascript">{html_escape(ex.get("code", ""))}</code></pre>\n'

            # Cross refs (both modes)
            if m.get("crossReferences"):
                refs = ", ".join(
                    f'<a href="#{r.split(".")[-1]}">{r}</a>'
                    for r in m["crossReferences"]
                )
                main += f"<p><strong>See also:</strong> {refs}</p>\n"

            main += "</div>\n"

    main += "</div>\n"

    # --- Assemble full HTML ---
    html = f"""<!DOCTYPE html>
<html><head>
<meta charset="utf-8">
<title>{class_name} ({mode_label}) - HISE Scripting API</title>
<link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
<style>
* {{ box-sizing: border-box; }}
body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Noto Sans", Helvetica, Arial, sans-serif; margin: 0; padding: 0; color: #e6edf3; background: #0d1117; line-height: 1.5; font-size: 16px; }}
code, pre, .signature {{ font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace; }}

/* Sidebar */
.sidebar {{ position: fixed; top: 0; left: 0; width: 220px; height: 100vh; background: #010409; border-right: 1px solid #21262d; padding: 16px 0; overflow-y: auto; }}
.sidebar-title {{ font-size: 1.1em; font-weight: 600; color: #e6edf3; padding: 0 16px 12px; border-bottom: 1px solid #21262d; margin-bottom: 8px; }}
.sidebar-link {{ display: block; padding: 4px 16px; color: #8b949e; text-decoration: none; font-size: 0.85em; transition: color 0.15s, background 0.15s; }}
.sidebar-link:hover {{ color: #e6edf3; background: #161b22; }}
.sidebar-link.active {{ color: #58a6ff; background: #161b22; border-right: 2px solid #58a6ff; }}
.sidebar-divider {{ font-size: 0.75em; color: #484f58; text-transform: uppercase; letter-spacing: 0.08em; padding: 12px 16px 4px; }}
.sidebar-method {{ font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace; font-size: 0.8em; }}

/* Main content */
.main {{ margin-left: 220px; max-width: 1012px; padding: 32px 32px 80px; }}
h1 {{ color: #e6edf3; font-weight: 600; font-size: 2em; border-bottom: 1px solid #21262d; padding-bottom: 0.3em; margin-bottom: 16px; }}
h2 {{ color: #e6edf3; font-weight: 600; font-size: 1.5em; margin-top: 32px; border-bottom: 1px solid #21262d; padding-bottom: 0.3em; }}
h3 {{ color: #e6edf3; font-weight: 600; font-size: 1.25em; margin-top: 24px; }}
p {{ margin: 0 0 16px; }}
.brief {{ font-size: 1.05em; color: #8b949e; margin-bottom: 16px; }}
.category {{ display: inline-block; background: #21262d; color: #8b949e; padding: 2px 10px; border-radius: 20px; font-size: 0.5em; margin-left: 12px; vertical-align: middle; }}
code {{ background: rgba(110,118,129,0.4); padding: 0.2em 0.4em; border-radius: 6px; font-size: 85%; color: #e6edf3; }}
pre {{ background: #161b22; padding: 16px; border-radius: 6px; overflow-x: auto; border: 1px solid #30363d; font-size: 85%; line-height: 1.45; }}
pre code {{ background: none; padding: 0; font-size: inherit; color: inherit; }}

/* Signature heading (h3.signature inside method cards) */
h3.signature {{ font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, monospace; font-size: 0.95em; font-weight: 500; color: #79c0ff; margin: 0 0 16px; }}

/* Tables */
table {{ border-collapse: collapse; width: 100%; margin: 8px 0 16px; }}
th, td {{ border: 1px solid #30363d; padding: 6px 13px; text-align: left; }}
th {{ background: #161b22; color: #e6edf3; font-weight: 600; }}
td {{ color: #c9d1d9; }}
tr:nth-child(even) {{ background: rgba(110,118,129,0.1); }}

/* Sidebar mode indicator */
.sidebar-mode {{ font-size: 0.7em; text-transform: uppercase; letter-spacing: 0.1em; padding: 4px 16px 8px; border-bottom: 1px solid #21262d; margin-bottom: 4px; }}
.mode-review {{ color: #8b949e; }}
.mode-web {{ color: #58a6ff; }}

/* Callout boxes */
.pitfall {{ background: #272115; border-left: 3px solid #d29922; padding: 8px 16px; margin: 8px 0 16px; border-radius: 0 6px 6px 0; color: #e6edf3; }}
.mistake {{ background: #2d1117; border-left: 3px solid #f85149; padding: 8px 16px; margin: 8px 0 16px; border-radius: 0 6px 6px 0; color: #e6edf3; }}

/* Method cards */
.method-card {{ margin: 24px 0; padding: 16px; background: #161b22; border-radius: 6px; border: 1px solid #30363d; }}

a {{ color: #58a6ff; text-decoration: none; }}
a:hover {{ text-decoration: underline; }}

/* Minimal example */
.minimal-example {{ margin: 4px 0 12px; }}
.minimal-example code {{ font-size: 0.85em; color: #7ee787; background: rgba(46,160,67,0.15); }}

/* Call scope LED */
.callscope-led {{ display: inline-block; width: 10px; height: 10px; border-radius: 50%; margin-left: 10px; vertical-align: middle; position: relative; top: -1px; }}
.callscope-led.scope-safe {{ background: #4E8E35; box-shadow: 0 0 4px #4E8E35; }}
.callscope-led.scope-warning {{ background: #FFBA00; box-shadow: 0 0 4px #FFBA00; }}
.callscope-led.scope-unsafe {{ background: #BB3434; box-shadow: 0 0 4px #BB3434; }}
.callscope-led.scope-init {{ background: #e6edf3; box-shadow: 0 0 4px #e6edf3; }}
.callscope-led.scope-unknown {{ background: #8b949e; }}

/* Disabled methods (review mode only) */
.method-disabled {{ opacity: 0.5; }}
h3.signature.disabled {{ color: #484f58; text-decoration: line-through; }}
.disabled-label {{ font-size: 0.85em; color: #d29922; margin: 4px 0; }}
.disabled-detail {{ font-size: 0.85em; color: #8b949e; margin: 4px 0; }}
</style>
</head>
<body>
{sidebar}
{main}
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-javascript.min.js"></script>
<script>
// Highlight active sidebar link on scroll
(function() {{
    const ids = [{ids_js}];
    const links = {{}};
    ids.forEach(id => {{
        const el = document.querySelector('.sidebar-link[href="#' + id + '"]');
        if (el) links[id] = el;
    }});
    const observer = new IntersectionObserver(entries => {{
        entries.forEach(entry => {{
            if (entry.isIntersecting && links[entry.target.id]) {{
                Object.values(links).forEach(l => l.classList.remove('active'));
                links[entry.target.id].classList.add('active');
            }}
        }});
    }}, {{ rootMargin: '0px 0px -70% 0px' }});
    ids.forEach(id => {{
        const el = document.getElementById(id);
        if (el) observer.observe(el);
    }});
}})();
</script>
</body></html>"""

    return html


def generate_class_markdown(class_name: str, c: dict) -> str:
    """Generate a clean markdown page for one class (web/userDocs mode only).

    This produces the same content and ordering as the HTML web preview
    but in plain markdown suitable for docs.hise.dev or other consumers.
    Structured fields (valueDescriptions, callbackProperties) are omitted --
    they exist for machine consumption only.
    """
    desc = c.get("description", {})
    methods = c.get("methods", {})
    lines = []

    # Header
    category = c.get("category", "")
    lines.append(f"# {class_name}")
    if category:
        lines.append(f"*{category}*")
    lines.append("")
    if desc.get("brief"):
        lines.append(desc["brief"])
        lines.append("")

    # Class-level userDocs
    if desc.get("userDocs"):
        lines.append("## Overview")
        lines.append("")
        lines.append(desc["userDocs"].strip())
        lines.append("")

    # Code example
    if desc.get("codeExample"):
        lines.append("## Usage Example")
        lines.append("")
        lines.append("```javascript")
        lines.append(desc["codeExample"].strip())
        lines.append("```")
        lines.append("")

    # Common mistakes
    if c.get("commonMistakes"):
        lines.append("## Common Mistakes")
        lines.append("")
        for m in c["commonMistakes"]:
            lines.append(f"- **Wrong:** {m['wrong']}")
            lines.append(f"  **Right:** {m['right']}")
            lines.append(f"  *{m['explanation']}*")
            lines.append("")

    # Methods
    if methods:
        lines.append("## Methods")
        lines.append("")

        for name, m in methods.items():
            # Skip disabled methods in clean markdown output
            if m.get("disabled"):
                continue

            sig = format_signature(class_name, name, m)
            lines.append(f"### `{sig}`")
            lines.append("")

            # Minimal example (right after signature)
            if m.get("minimalExample"):
                lines.append(f"`{m['minimalExample']}`")
                lines.append("")

            # Parameter table (right after signature)
            if m.get("parameters"):
                lines.append("| Parameter | Type | Description |")
                lines.append("|-----------|------|-------------|")
                for p in m["parameters"]:
                    pt = display_type(p.get("type", "var")) or "var"
                    lines.append(
                        f"| `{p.get('name', '')}` "
                        f"| `{pt}` "
                        f"| {p.get('description', '')} |"
                    )
                lines.append("")

            # userDocs prose (or fall back to base description)
            if m.get("userDocs"):
                lines.append(m["userDocs"].strip())
                lines.append("")
            elif m.get("description"):
                lines.append(m["description"])
                lines.append("")

            # Pitfalls
            for p in m.get("pitfalls", []):
                lines.append(f"> **Warning:** {p.get('description', '')}")
                lines.append("")

            # Examples
            for ex in m.get("examples", []):
                lines.append("```javascript")
                lines.append(ex.get("code", "").strip())
                lines.append("```")
                lines.append("")

            # Cross references
            if m.get("crossReferences"):
                refs = ", ".join(m["crossReferences"])
                lines.append(f"**See also:** {refs}")
                lines.append("")

            lines.append("---")
            lines.append("")

    return "\n".join(lines)


def run_filter_binary(output_path=None):
    """Filter merged JSON -> minimal JSON for C++ binary embedding."""
    input_path = OUTPUT_DIR / "api_reference.json"
    if not input_path.is_file():
        print("ERROR: No merged JSON found. Run 'merge' first.")
        sys.exit(1)

    if output_path is None:
        output_path = OUTPUT_DIR / "filtered_api.json"
    else:
        output_path = Path(output_path)

    with open(input_path, "r", encoding="utf-8") as f:
        full_api = json.load(f)

    filtered = {"classes": {}}

    for class_name, class_data in full_api.get("classes", {}).items():
        methods_out = {}

        for method_name, method_data in class_data.get("methods", {}).items():
            # Skip disabled methods
            if method_data.get("disabled"):
                continue

            # Reconstruct arguments string
            params = method_data.get("parameters", [])
            if params:
                param_strs = [f"{p.get('type', 'var')} {p['name']}" for p in params]
                arguments = "(" + ", ".join(param_strs) + ")"
            else:
                arguments = "()"

            # Extract brief description (first sentence, max ~200 chars)
            desc = method_data.get("description", "")
            brief = _extract_brief(desc)

            entry = {
                "name": method_name,
                "arguments": arguments,
                "returnType": method_data.get("returnType", ""),
                "description": brief,
            }

            # Only include callScope if present and valid
            call_scope = method_data.get("callScope")
            if call_scope in ("safe", "warning", "unsafe", "init"):
                entry["callScope"] = call_scope

            call_scope_note = method_data.get("callScopeNote")
            if call_scope_note:
                entry["callScopeNote"] = call_scope_note

            methods_out[method_name] = entry

        if methods_out:
            filtered["classes"][class_name] = {"methods": methods_out}

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(filtered, f, indent=2, ensure_ascii=False)

    class_count = len(filtered["classes"])
    method_count = sum(len(c["methods"]) for c in filtered["classes"].values())
    print(f"Filter-binary complete:")
    print(f"  Classes: {class_count}")
    print(f"  Methods: {method_count}")
    print(f"  Output: {output_path}")


def _extract_brief(description: str, max_len: int = 200) -> str:
    """Extract first sentence from a description, capped at max_len."""
    if not description:
        return ""
    # Find first sentence boundary
    for sep in (". ", ".\n"):
        idx = description.find(sep)
        if idx != -1:
            brief = description[:idx + 1]
            if len(brief) <= max_len:
                return brief
            break
    # No sentence boundary or first sentence too long: truncate
    if len(description) <= max_len:
        return description
    # Truncate at last space before max_len
    trunc = description[:max_len]
    last_space = trunc.rfind(" ")
    if last_space > max_len // 2:
        return trunc[:last_space]
    return trunc


def run_preview(class_filter: str = None):
    """Generate HTML preview pages from api_reference.json."""
    json_path = OUTPUT_DIR / "api_reference.json"
    if not json_path.is_file():
        print("ERROR: No api_reference.json found. Run 'merge' first.")
        sys.exit(1)

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    PREVIEW_DIR.mkdir(parents=True, exist_ok=True)
    images_dir = PREVIEW_DIR / "images"
    images_dir.mkdir(parents=True, exist_ok=True)

    classes = data.get("classes", {})
    if class_filter:
        # Case-insensitive lookup
        name_map = {k.lower(): k for k in classes}
        canonical = name_map.get(class_filter.lower())
        if not canonical:
            print(f"ERROR: Class '{class_filter}' not found in api_reference.json.")
            sys.exit(1)
        targets = {canonical: classes[canonical]}
    else:
        # Only generate for classes that have enrichment data (brief != base description)
        targets = {}
        for name, c in classes.items():
            p1_dir = PHASE1_DIR / name
            if p1_dir.is_dir():
                targets[name] = c
        if not targets:
            print("No enriched classes found. Run Phase 1 for at least one class.")
            sys.exit(1)

    page_count = 0
    for name, c in targets.items():
        # Always generate the review page (raw analysis)
        html_review = generate_class_html(name, c, mode="review")
        out_review = PREVIEW_DIR / f"{name}_review.html"
        with open(out_review, "w", encoding="utf-8") as f:
            f.write(html_review)
        print(f"  {out_review}")
        page_count += 1

        # Generate web page (userDocs) if any userDocs exist
        has_userdocs = (
            c.get("description", {}).get("userDocs") is not None
            or any(
                m.get("userDocs") is not None
                for m in c.get("methods", {}).values()
            )
        )
        if has_userdocs:
            html_web = generate_class_html(name, c, mode="web")
            out_web = PREVIEW_DIR / f"{name}.html"
            with open(out_web, "w", encoding="utf-8") as f:
                f.write(html_web)
            print(f"  {out_web}")
            page_count += 1

            # Generate clean markdown (same content as web HTML)
            md_text = generate_class_markdown(name, c)
            out_md = PREVIEW_DIR / f"{name}.md"
            with open(out_md, "w", encoding="utf-8") as f:
                f.write(md_text)
            print(f"  {out_md}")
            page_count += 1

        # Copy SVG diagrams to preview/images/ (manual overrides auto)
        svg_count = 0
        for phase4_dir in (PHASE4_MANUAL_DIR, PHASE4_AUTO_DIR):
            svg_dir = phase4_dir / name
            if svg_dir.is_dir():
                for svg_file in svg_dir.glob("*.svg"):
                    dest = images_dir / svg_file.name
                    if not dest.exists() or phase4_dir == PHASE4_MANUAL_DIR:
                        shutil.copy2(svg_file, dest)
                        svg_count += 1
        if svg_count:
            print(f"  Copied {svg_count} SVG(s) to preview/images/")

    print(f"Preview: {page_count} page(s) generated.")


# ===================================================================
# CLI
# ===================================================================

def main():
    parser = argparse.ArgumentParser(
        description="API Enrichment Pipeline CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    subparsers = parser.add_subparsers(dest="command", help="Subcommand to run")

    subparsers.add_parser(
        "phase0",
        help="Parse Doxygen XML → base JSON (mechanical, no AI)",
    )
    subparsers.add_parser(
        "prepare",
        help="Print worklist of unscanned classes/methods",
    )
    subparsers.add_parser(
        "merge",
        help="Merge all phases → output/api_reference.json",
    )
    preview_parser = subparsers.add_parser(
        "preview",
        help="Generate HTML preview pages from merged JSON",
    )
    preview_parser.add_argument(
        "classname", nargs="?", default=None,
        help="Class name to preview (default: all enriched classes)",
    )

    filter_binary_parser = subparsers.add_parser(
        "filter-binary",
        help="Filter merged JSON -> minimal JSON for C++ binary embedding",
    )
    filter_binary_parser.add_argument(
        "output", nargs="?", default=None,
        help="Output path (default: enrichment/output/filtered_api.json)",
    )

    args = parser.parse_args()

    if args.command == "phase0":
        run_phase0()
    elif args.command == "prepare":
        run_prepare()
    elif args.command == "merge":
        run_merge()
    elif args.command == "preview":
        run_preview(args.classname)
    elif args.command == "filter-binary":
        run_filter_binary(args.output)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
