#!/usr/bin/env python3
"""
API Enrichment Pipeline CLI

Produces a comprehensive api_reference.json from Doxygen XML, AI-generated
analysis, project examples, and manual overrides.

Subcommands:
    phase0   - Parse Doxygen XML → base JSON (mechanical)
    prepare  - Print worklist of unscanned classes/methods
    merge    - Merge all phases → output/api_reference.json
    preview  - Generate HTML preview pages from merged JSON

Usage:
    python api_enrich.py phase0
    python api_enrich.py prepare
    python api_enrich.py merge
    python api_enrich.py preview [ClassName]
"""

import argparse
import json
import os
import re
import sys
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from html import escape as html_escape
from pathlib import Path

# ---------------------------------------------------------------------------
# Paths (relative to this script's directory)
# ---------------------------------------------------------------------------

SCRIPT_DIR = Path(__file__).resolve().parent
XML_SELECTION_DIR = SCRIPT_DIR / "xml" / "selection"
ENRICHMENT_DIR = SCRIPT_DIR / "enrichment"
BASE_DIR = ENRICHMENT_DIR / "base"
PHASE1_DIR = ENRICHMENT_DIR / "phase1"
PHASE2_DIR = ENRICHMENT_DIR / "phase2"
PHASE3_DIR = ENRICHMENT_DIR / "phase3"
PHASE4_AUTO_DIR = ENRICHMENT_DIR / "phase4" / "auto"
PHASE4_MANUAL_DIR = ENRICHMENT_DIR / "phase4" / "manual"
OUTPUT_DIR = ENRICHMENT_DIR / "output"
SCANNED_FILE = ENRICHMENT_DIR / "phase1_scanned.txt"

# ---------------------------------------------------------------------------
# Category mapping: friendly class name → category
# Derived from batchCreate.bat rename mappings.
# ---------------------------------------------------------------------------

CATEGORY_MAP = {
    # namespace — global API namespaces
    "Array": "namespace",
    "Colours": "namespace",
    "Console": "namespace",
    "Content": "namespace",
    "Date": "namespace",
    "Engine": "namespace",
    "FileSystem": "namespace",
    "Math": "namespace",
    "Message": "namespace",
    "ModuleIds": "namespace",
    "Sampler": "namespace",
    "Server": "namespace",
    "Settings": "namespace",
    "String": "namespace",
    "Synth": "namespace",
    "Threads": "namespace",
    "TransportHandler": "namespace",

    # object — instances obtained via factory methods or module references
    "AudioFile": "object",
    "AudioSampleProcessor": "object",
    "BackgroundTask": "object",
    "BeatportManager": "object",
    "Broadcaster": "object",
    "Buffer": "object",
    "Builder": "object",
    "ChildSynth": "object",
    "ComplexGroupManager": "object",
    "ContainerChild": "object",
    "DisplayBuffer": "object",
    "DisplayBufferSource": "object",
    "Download": "object",
    "DspModule": "object",
    "Effect": "object",
    "ErrorHandler": "object",
    "Expansion": "object",
    "ExpansionHandler": "object",
    "FFT": "object",
    "File": "object",
    "FixObjectArray": "object",
    "FixObjectFactory": "object",
    "FixObjectStack": "object",
    "GlobalCable": "object",
    "GlobalRoutingManager": "object",
    "Graphics": "object",
    "LorisManager": "object",
    "MacroHandler": "object",
    "MarkdownRenderer": "object",
    "MessageHolder": "object",
    "MidiAutomationHandler": "object",
    "MidiList": "object",
    "MidiPlayer": "object",
    "MidiProcessor": "object",
    "Modifiers": "object",
    "Modulator": "object",
    "NeuralNetwork": "object",
    "Path": "object",
    "PresetStorage": "object",
    "Rectangle": "object",
    "RoutingMatrix": "object",
    "Sample": "object",
    "ScriptLookAndFeel": "object",
    "ScriptModulationMatrix": "object",
    "ScriptShader": "object",
    "SliderPackData": "object",
    "SliderPackProcessor": "object",
    "SlotFX": "object",
    "Table": "object",
    "TableProcessor": "object",
    "ThreadSafeStorage": "object",
    "Timer": "object",
    "Unlocker": "object",
    "UnorderedStack": "object",
    "UserPresetHandler": "object",
    "WavetableController": "object",

    # component — UI components created via Content.addX()
    "ScriptAudioWaveform": "component",
    "ScriptButton": "component",
    "ScriptComboBox": "component",
    "ScriptDynamicContainer": "component",
    "ScriptFloatingTile": "component",
    "ScriptImage": "component",
    "ScriptLabel": "component",
    "ScriptMultipageDialog": "component",
    "ScriptPanel": "component",
    "ScriptSlider": "component",
    "ScriptSliderPack": "component",
    "ScriptTable": "component",
    "ScriptWebView": "component",
    "ScriptedViewport": "component",

    # component — not generated by last Doxygen run but present in batchCreate.bat
    "ModulatorMeter": "component",
    "ScriptedPlotter": "component",

    # scriptnode — ScriptNode DSP classes
    "Connection": "scriptnode",
    "DspNetwork": "scriptnode",
    "NetworkTest": "scriptnode",
    "Node": "scriptnode",
    "Parameter": "scriptnode",
}

# ---------------------------------------------------------------------------
# Filtering: infrastructure method exclusion
# ---------------------------------------------------------------------------

# Method names that are always infrastructure, even if they have descriptions
INFRASTRUCTURE_METHODS = {
    "getObjectName", "getClassName", "allowIllegalCallsOnAudioThread",
    "setDebugLocation", "timerCallback", "allowRefCount",
    "isControlCallbackPending",       # REST API internal (ScriptComponent)
    "updateContentPropertyInternal",  # Internal property update (ScriptComponent)
}

# C++ type substrings that indicate a non-scriptable (infrastructure) method.
# If any parameter type or the return type contains one of these, the method
# is excluded from the scripting API surface.
NON_SCRIPTABLE_TYPE_PATTERNS = [
    "Component",
    "MouseEvent",
    "HiseJavascriptEngine",
    "ValueTree",
    "DebugableObjectBase",
    "NotificationType",
    "KeyPress",
    "ZLevelListener",
    "ProfileCollection",
    "WeakCallbackHolder",
    "SubComponentListener",
    "NativeFunctionArgs",
    "Identifier",
    "Location",
]

# ---------------------------------------------------------------------------
# C++ type normalization for Phase 0 output
# ---------------------------------------------------------------------------

TYPE_NORMALIZATIONS = {
    "const String &": "String",
    "const String&": "String",
    "String &": "String",
    "String&": "String",
    "const var &": "var",
    "const var&": "var",
    "var &": "var",
    "var&": "var",
}


def normalize_cpp_type(raw_type: str) -> str:
    """Normalize a C++ type string for the base JSON output."""
    t = raw_type.strip()
    # Apply exact normalizations first
    if t in TYPE_NORMALIZATIONS:
        return TYPE_NORMALIZATIONS[t]
    # Strip leading 'const ' and trailing ' &' / '&' for remaining types
    t = re.sub(r"^const\s+", "", t)
    t = re.sub(r"\s*&$", "", t)
    return t.strip()


def contains_non_scriptable_type(type_str: str) -> bool:
    """Check if a type string contains a non-scriptable C++ type."""
    for pattern in NON_SCRIPTABLE_TYPE_PATTERNS:
        if pattern in type_str:
            return True
    return False


# ---------------------------------------------------------------------------
# XML text extraction helpers
# ---------------------------------------------------------------------------

def get_text_content(element) -> str:
    """Recursively extract all text from an XML element and its children."""
    if element is None:
        return ""
    parts = []
    if element.text:
        parts.append(element.text)
    for child in element:
        parts.append(get_text_content(child))
        if child.tail:
            parts.append(child.tail)
    return "".join(parts).strip()


def get_description(memberdef) -> str:
    """Extract the description text from a memberdef's detaileddescription."""
    detailed = memberdef.find("detaileddescription")
    if detailed is None:
        return ""
    return get_text_content(detailed)


# ===================================================================
# PHASE 0: Doxygen XML → Base JSON
# ===================================================================

def run_phase0():
    """Parse all Doxygen XML files in xml/selection/ and produce base JSON."""
    if not XML_SELECTION_DIR.is_dir():
        print(f"ERROR: XML selection directory not found: {XML_SELECTION_DIR}")
        sys.exit(1)

    BASE_DIR.mkdir(parents=True, exist_ok=True)

    xml_files = sorted(XML_SELECTION_DIR.glob("*.xml"))
    if not xml_files:
        print(f"ERROR: No XML files found in {XML_SELECTION_DIR}")
        sys.exit(1)

    total_classes = 0
    total_methods = 0
    skipped_infra = 0

    for xml_path in xml_files:
        class_name = xml_path.stem  # e.g., "Console" from "Console.xml"

        # Skip files not in our category map (shouldn't happen, but be safe)
        if class_name not in CATEGORY_MAP:
            print(f"  WARNING: {class_name} not in category map, skipping")
            continue

        try:
            tree = ET.parse(xml_path)
        except ET.ParseError:
            # Some Doxygen XML files contain invalid characters (e.g., degree
            # symbol in Math.xml). Re-read as bytes, strip non-XML chars, retry.
            try:
                raw = xml_path.read_bytes()
                # Strip bytes outside the valid XML 1.0 character range
                cleaned = bytes(b for b in raw if b == 0x09 or b == 0x0A
                                or b == 0x0D or 0x20 <= b < 0x7F)
                tree = ET.ElementTree(ET.fromstring(cleaned))
            except Exception as e2:
                print(f"  ERROR: Failed to parse {xml_path} even after "
                      f"cleaning: {e2}")
                continue

        root = tree.getroot()
        compounddef = root.find("compounddef")
        if compounddef is None:
            print(f"  WARNING: No compounddef in {xml_path}, skipping")
            continue

        # Class-level description
        class_desc = get_description(compounddef)

        # Collect public methods
        methods = {}
        for sectiondef in compounddef.findall("sectiondef"):
            kind = sectiondef.get("kind", "")
            if kind not in ("public-func", "public-static-func"):
                continue

            for memberdef in sectiondef.findall("memberdef"):
                if memberdef.get("kind") != "function":
                    continue

                name = get_text_content(memberdef.find("name"))
                return_type_raw = get_text_content(memberdef.find("type"))

                # --- Exclusion filters ---

                # 1. Skip constructors (empty return type) and destructors
                if not return_type_raw or name.startswith("~"):
                    continue

                # 2. Skip known infrastructure method names
                if name in INFRASTRUCTURE_METHODS:
                    skipped_infra += 1
                    continue

                # 3. Skip methods with empty descriptions
                desc = get_description(memberdef)
                if not desc:
                    skipped_infra += 1
                    continue

                # 4. Skip methods with non-scriptable types in return or params
                if contains_non_scriptable_type(return_type_raw):
                    skipped_infra += 1
                    continue

                param_has_non_scriptable = False
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    if contains_non_scriptable_type(param_type_raw):
                        param_has_non_scriptable = True
                        break
                if param_has_non_scriptable:
                    skipped_infra += 1
                    continue

                # --- Extract method data ---

                return_type = normalize_cpp_type(return_type_raw)

                parameters = []
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    param_name_el = param.find("declname")
                    param_name = get_text_content(param_name_el) if param_name_el is not None else ""
                    param_type = normalize_cpp_type(param_type_raw)

                    if param_name:  # Skip unnamed parameters
                        parameters.append({
                            "name": param_name,
                            "type": param_type,
                        })

                # Build signature string
                param_strs = [f"{p['type']} {p['name']}" for p in parameters]
                signature = f"{return_type} {name}({', '.join(param_strs)})"

                methods[name] = {
                    "signature": signature,
                    "returnType": return_type,
                    "description": desc,
                    "parameters": parameters,
                }

                total_methods += 1

        # Write base JSON
        base_json = {
            "className": class_name,
            "category": CATEGORY_MAP[class_name],
            "description": class_desc,
            "methods": methods,
        }

        output_path = BASE_DIR / f"{class_name}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(base_json, f, indent=2, ensure_ascii=False)

        total_classes += 1

    print(f"Phase 0 complete:")
    print(f"  Classes processed: {total_classes}")
    print(f"  Methods extracted: {total_methods}")
    print(f"  Infrastructure methods filtered: {skipped_infra}")
    print(f"  Output: {BASE_DIR}")


# ===================================================================
# PREPARE: Print worklist of unscanned classes/methods
# ===================================================================

def _get_phase4_authored(class_name: str) -> tuple:
    """Return (auto_set, manual_set, has_auto_readme, has_manual_readme)
    for a given class, checking both phase4/auto and phase4/manual dirs."""
    auto_set = set()
    manual_set = set()
    has_auto_readme = False
    has_manual_readme = False

    auto_dir = PHASE4_AUTO_DIR / class_name
    manual_dir = PHASE4_MANUAL_DIR / class_name

    if auto_dir.is_dir():
        has_auto_readme = (auto_dir / "Readme.md").is_file()
        for md_file in auto_dir.glob("*.md"):
            if md_file.name.lower() != "readme.md":
                auto_set.add(md_file.stem.lower())

    if manual_dir.is_dir():
        has_manual_readme = (manual_dir / "Readme.md").is_file()
        for md_file in manual_dir.glob("*.md"):
            if md_file.name.lower() != "readme.md":
                manual_set.add(md_file.stem.lower())

    return auto_set, manual_set, has_auto_readme, has_manual_readme


def run_prepare():
    """Read base JSON and scanned manifest, print unscanned worklist."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    # Read scanned manifest
    scanned = set()
    if SCANNED_FILE.is_file():
        with open(SCANNED_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    scanned.add(line)

    # Read all base JSON files
    total_remaining = 0
    total_scanned = 0
    worklist = []

    # Phase 4 tracking
    p4_total_needed = 0
    p4_total_auto = 0
    p4_total_manual = 0
    p4_worklist = []

    for json_path in sorted(BASE_DIR.glob("*.json")):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        class_name = data["className"]
        methods = data.get("methods", {})

        # Phase 1 worklist
        unscanned_methods = []
        for method_name in sorted(methods.keys()):
            key = f"{class_name}.{method_name}"
            if key in scanned:
                total_scanned += 1
            else:
                unscanned_methods.append(method_name)
                total_remaining += 1

        if unscanned_methods:
            worklist.append((class_name, data.get("category", "?"), unscanned_methods))

        # Phase 4 worklist -- only for classes that have Phase 1 data
        p1_dir = PHASE1_DIR / class_name
        if p1_dir.is_dir():
            auto_set, manual_set, has_auto_readme, has_manual_readme = \
                _get_phase4_authored(class_name)
            authored = auto_set | manual_set
            needs_docs = []
            for method_name in sorted(methods.keys()):
                if method_name.lower() not in authored:
                    needs_docs.append(method_name)
                    p4_total_needed += 1
                elif method_name.lower() in manual_set:
                    p4_total_manual += 1
                else:
                    p4_total_auto += 1

            needs_readme = not has_auto_readme and not has_manual_readme
            if needs_docs or needs_readme:
                p4_worklist.append((class_name, needs_readme, needs_docs))

    # Print Phase 1 worklist
    if not worklist:
        print("Phase 1: All methods scanned.")
        print(f"  Total scanned: {total_scanned}")
    else:
        print(f"Phase 1: {total_remaining} methods remaining across {len(worklist)} classes")
        print(f"  Already scanned: {total_scanned}")
        print()
        for class_name, category, methods in worklist:
            print(f"  {class_name} [{category}] -- {len(methods)} methods:")
            for m in methods:
                print(f"    - {m}")
            print()

    # Print Phase 4 worklist
    print()
    if not p4_worklist:
        print("Phase 4: All enriched classes have userDocs.")
        print(f"  Auto: {p4_total_auto}, Manual: {p4_total_manual}")
    else:
        print(f"Phase 4: {p4_total_needed} methods need userDocs across {len(p4_worklist)} classes")
        print(f"  Already authored: {p4_total_auto} auto, {p4_total_manual} manual")
        print()
        for class_name, needs_readme, methods in p4_worklist:
            readme_note = " (+ Readme.md)" if needs_readme else ""
            print(f"  {class_name} -- {len(methods)} methods{readme_note}")
        print()


# ===================================================================
# MERGE: Combine all phases → output/api_reference.json
# ===================================================================

# --- Markdown parsing utilities ---

def parse_readme_md(filepath: Path) -> dict:
    """Parse a Phase 1/3 Readme.md into a structured dict.

    Expected sections: Brief, Purpose, Details, obtainedVia, Constants,
    Dynamic Constants, Common Mistakes, codeExample, Alternatives,
    Related Preprocessors.
    """
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    result = {}

    # Extract sections by ## headings
    sections = split_by_headings(content, level=2)

    if "Brief" in sections:
        result["brief"] = sections["Brief"].strip()

    if "Purpose" in sections:
        result["purpose"] = sections["Purpose"].strip()

    if "Details" in sections:
        details = sections["Details"].strip()
        if details:
            result["details"] = details

    if "obtainedVia" in sections:
        text = sections["obtainedVia"].strip()
        # Strip backticks if wrapped
        text = text.strip("`")
        result["obtainedVia"] = text

    if "codeExample" in sections:
        result["codeExample"] = extract_code_block(sections["codeExample"])

    if "Alternatives" in sections:
        text = sections["Alternatives"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            result["alternatives"] = text

    if "Related Preprocessors" in sections:
        text = sections["Related Preprocessors"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            # Parse preprocessor names: first backtick-wrapped token per
            # bullet line, or comma-separated plain names as fallback.
            preprocessors = []
            for line in text.splitlines():
                line = line.strip().lstrip("-").strip()
                if not line:
                    continue
                m = re.match(r"`([^`]+)`", line)
                if m:
                    preprocessors.append(m.group(1))
            if not preprocessors:
                preprocessors = [p.strip() for p in text.split(",") if p.strip()]
            if preprocessors:
                result["relatedPreprocessors"] = preprocessors

    if "Constants" in sections:
        result["constants"] = parse_markdown_table(sections["Constants"])

    if "Dynamic Constants" in sections:
        result["dynamicConstants"] = parse_markdown_table(sections["Dynamic Constants"])

    if "Common Mistakes" in sections:
        result["commonMistakes"] = parse_markdown_table(sections["Common Mistakes"])

    return result


def parse_methods_md(filepath: Path) -> dict:
    """Parse a Phase 1 methods.md into a dict of method_name → method_data."""
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    methods = {}
    # Split by ## headings (level 2) — each is a method
    method_sections = split_by_headings(content, level=2)

    for method_name, body in method_sections.items():
        method_data = parse_single_method(body)
        if method_data:
            methods[method_name] = method_data

    return methods


def parse_method_override_md(filepath: Path) -> dict:
    """Parse a Phase 2/3 method override file (single method).

    Supports two formats:
    1. Structured format with **Signature:**, **Description:**, etc.
    2. Raw docs format: prose paragraph(s) followed by ```code``` blocks.
       Description = everything before the first code fence.
       Examples = all fenced code blocks.
    """
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    # Strip a leading ## heading if present (method name is inferred
    # from the filename, so the heading is optional).
    content_stripped = re.sub(r"^##\s+\S+.*\n", "", content, count=1)

    result = parse_single_method(content_stripped)
    if result:
        return result

    # Fallback: raw docs format.
    # Split at the first ``` fence.  Everything before it is description,
    # all fenced blocks are examples.
    fence_idx = content.find("```")
    if fence_idx == -1:
        # No code blocks -- entire content is description
        desc = content.strip()
        if desc:
            return {"description": desc}
        return {}

    desc = content[:fence_idx].strip()
    examples = parse_examples(content[fence_idx:])

    result = {}
    if desc:
        result["description"] = desc
    if examples:
        result["examples"] = examples
    return result


def parse_single_method(body: str) -> dict:
    """Parse a single method's markdown body into structured data."""
    result = {}

    # Extract bold-prefixed fields
    sig_match = re.search(r"\*\*Signature:\*\*\s*`([^`]+)`", body)
    if sig_match:
        result["signature"] = sig_match.group(1)

    rt_match = re.search(r"\*\*Return Type:\*\*\s*`?([^`\n]+)`?", body)
    if rt_match:
        result["returnType"] = rt_match.group(1).strip()

    rts_match = re.search(r"\*\*Realtime Safe:\*\*\s*(\S+)", body)
    if rts_match:
        val = rts_match.group(1).strip().lower()
        if val == "true":
            result["realtimeSafe"] = True
        elif val == "false":
            result["realtimeSafe"] = False
        else:
            result["realtimeSafe"] = None

    # Description
    desc_match = re.search(
        r"\*\*Description:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if desc_match:
        result["description"] = desc_match.group(1).strip()

    # Parameters table
    params_match = re.search(
        r"\*\*Parameters:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if params_match:
        params_text = params_match.group(1)
        params = parse_parameter_table(params_text)
        if params:
            result["parameters"] = params

    # Pitfalls
    pitfalls_match = re.search(
        r"\*\*Pitfalls:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if pitfalls_match:
        pitfalls_text = pitfalls_match.group(1)
        pitfalls = parse_bullet_list(pitfalls_text)
        if pitfalls:
            result["pitfalls"] = pitfalls

    # Cross References
    xref_match = re.search(
        r"\*\*Cross References:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if xref_match:
        xref_text = xref_match.group(1)
        xrefs = []
        for line in xref_text.strip().splitlines():
            line = line.strip().lstrip("-").strip()
            # Remove backticks
            line = line.strip("`")
            if line:
                xrefs.append(line)
        if xrefs:
            result["crossReferences"] = xrefs

    # Example(s)
    example_match = re.search(
        r"\*\*Example(?:s)?:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if example_match:
        examples = parse_examples(example_match.group(1))
        if examples:
            result["examples"] = examples

    return result


# --- Markdown parsing helpers ---

def split_by_headings(content: str, level: int = 2) -> dict:
    """Split markdown content by headings of a given level.
    Returns dict of heading_text → body_text.
    """
    prefix = "#" * level
    pattern = rf"^{prefix}\s+(.+)$"
    sections = {}
    current_heading = None
    current_lines = []

    for line in content.splitlines():
        match = re.match(pattern, line)
        if match:
            if current_heading is not None:
                sections[current_heading] = "\n".join(current_lines)
            current_heading = match.group(1).strip()
            current_lines = []
        elif current_heading is not None:
            current_lines.append(line)

    if current_heading is not None:
        sections[current_heading] = "\n".join(current_lines)

    return sections


def extract_code_block(text: str) -> str:
    """Extract the content of the first fenced code block."""
    match = re.search(r"```\w*\n(.*?)```", text, re.DOTALL)
    if match:
        return match.group(1).strip()
    # Fall back to the raw text
    return text.strip()


def parse_markdown_table(text: str) -> list:
    """Parse a pipe-delimited markdown table into a list of dicts.
    First row is headers, second row is separator, rest are data.
    """
    lines = [l.strip() for l in text.strip().splitlines() if l.strip()]
    # Find table lines (contain |)
    table_lines = [l for l in lines if "|" in l]
    if len(table_lines) < 3:
        return []

    # Parse header
    headers = [h.strip() for h in table_lines[0].split("|") if h.strip()]

    # Skip separator (table_lines[1])
    rows = []
    for line in table_lines[2:]:
        cells = [c.strip() for c in line.split("|") if c.strip()]
        if len(cells) >= len(headers):
            row = {}
            for i, header in enumerate(headers):
                row[header] = cells[i] if i < len(cells) else ""
            rows.append(row)

    return rows


def parse_parameter_table(text: str) -> list:
    """Parse a parameter table from method markdown."""
    rows = parse_markdown_table(text)
    params = []
    for row in rows:
        param = {
            "name": row.get("Name", ""),
            "type": row.get("Type", ""),
            "forcedType": row.get("Forced", "").lower() in ("yes", "true"),
            "description": row.get("Description", ""),
        }
        constraints = row.get("Constraints", "")
        if constraints and constraints != "—":
            param["constraints"] = constraints
        params.append(param)
    return params


def parse_bullet_list(text: str) -> list:
    """Parse a markdown bullet list into a list of strings."""
    items = []
    for line in text.strip().splitlines():
        line = line.strip()
        if line.startswith("- "):
            items.append(line[2:].strip())
        elif line.startswith("* "):
            items.append(line[2:].strip())
    return items


def parse_examples(text: str) -> list:
    """Parse example sections from method markdown."""
    examples = []

    # Find all code blocks, optionally preceded by a title comment
    blocks = re.findall(
        r"(?:(?://\s*(.+)\n)|(?:###\s*(.+)\n))?```\w*\n(.*?)```",
        text, re.DOTALL
    )

    if blocks:
        for title_comment, title_heading, code in blocks:
            title = (title_heading or title_comment or "").strip()
            examples.append({
                "title": title or "Example",
                "code": code.strip(),
            })
    else:
        # Single code block without fence
        code = text.strip()
        if code:
            examples.append({
                "title": "Example",
                "code": code,
            })

    return examples


# --- Merge logic ---

def build_class_description(base_desc: str, readme_data: dict, source_tag: str) -> dict:
    """Build the class description object from base + readme data."""
    desc = {
        "brief": readme_data.get("brief"),
        "purpose": readme_data.get("purpose"),
        "details": readme_data.get("details"),
        "obtainedVia": readme_data.get("obtainedVia"),
        "codeExample": readme_data.get("codeExample"),
        "alternatives": readme_data.get("alternatives"),
        "relatedPreprocessors": readme_data.get("relatedPreprocessors", []),
        "userGuidePage": None,
    }

    # If no enrichment data, use the base description for brief/purpose
    if desc["brief"] is None and base_desc:
        desc["brief"] = base_desc
    if desc["purpose"] is None and base_desc:
        desc["purpose"] = base_desc

    return desc


def build_constants(readme_data: dict, source_tag: str) -> dict:
    """Build constants dict from parsed readme table rows."""
    constants = {}
    for row in readme_data.get("constants", []):
        name = row.get("Name", "")
        if not name:
            continue
        value = row.get("Value", "")
        # Try to parse numeric values
        try:
            value = int(value)
        except (ValueError, TypeError):
            try:
                value = float(value)
            except (ValueError, TypeError):
                pass

        constants[name] = {
            "value": value,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "group": row.get("Group", None) or None,
            "source": source_tag,
        }
    return constants


def build_dynamic_constants(readme_data: dict, source_tag: str) -> dict:
    """Build dynamic constants dict from parsed readme table rows."""
    dyn_constants = {}
    for row in readme_data.get("dynamicConstants", []):
        name = row.get("Name", "")
        if not name:
            continue
        dyn_constants[name] = {
            "value": None,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "source": source_tag,
        }
    return dyn_constants


def build_common_mistakes(readme_data: dict, source_tag: str) -> list:
    """Build common mistakes list from parsed readme table rows."""
    mistakes = []
    for row in readme_data.get("commonMistakes", []):
        mistakes.append({
            "wrong": row.get("Wrong", ""),
            "right": row.get("Right", ""),
            "explanation": row.get("Explanation", ""),
            "source": source_tag,
        })
    return mistakes


def build_method_entry(base_method: dict, enriched: dict, source_tag: str) -> dict:
    """Build a full method entry by merging base data with enrichment."""
    entry = {
        "signature": enriched.get("signature", base_method.get("signature", "")),
        "returnType": enriched.get("returnType", base_method.get("returnType", "")),
        "description": enriched.get("description", base_method.get("description", "")),
        "parameters": [],
        "realtimeSafe": enriched.get("realtimeSafe"),
        "crossReferences": enriched.get("crossReferences", []),
        "pitfalls": [],
        "examples": [],
    }

    # Parameters: prefer enriched (has forcedType info), fall back to base
    if enriched.get("parameters"):
        entry["parameters"] = enriched["parameters"]
    else:
        # Convert base params (no forcedType info)
        for p in base_method.get("parameters", []):
            entry["parameters"].append({
                "name": p["name"],
                "type": p["type"],
                "forcedType": False,
                "description": p.get("description", ""),
            })

    # Pitfalls: tagged list items
    for pitfall_text in enriched.get("pitfalls", []):
        if isinstance(pitfall_text, dict):
            entry["pitfalls"].append(pitfall_text)
        else:
            entry["pitfalls"].append({
                "description": pitfall_text,
                "source": source_tag,
            })

    # Examples
    for ex in enriched.get("examples", []):
        if isinstance(ex, dict):
            if "source" not in ex:
                ex["source"] = source_tag
            entry["examples"].append(ex)
        else:
            entry["examples"].append({
                "title": "Example",
                "code": str(ex),
                "context": "",
                "source": source_tag,
            })

    return entry


def merge_method_entries(existing: dict, override: dict, source_tag: str) -> dict:
    """Merge an override method entry into an existing one.
    Last-writer-wins for most fields; union merge for pitfalls/crossRefs.
    """
    # Last-writer-wins fields
    if override.get("signature"):
        existing["signature"] = override["signature"]
    if override.get("returnType"):
        existing["returnType"] = override["returnType"]
    if override.get("description"):
        existing["description"] = override["description"]
    if override.get("parameters"):
        existing["parameters"] = override["parameters"]
    if "realtimeSafe" in override and override["realtimeSafe"] is not None:
        existing["realtimeSafe"] = override["realtimeSafe"]

    # Examples: last-writer-wins (entire array replaced)
    if override.get("examples"):
        existing["examples"] = []
        for ex in override["examples"]:
            if isinstance(ex, dict):
                if "source" not in ex:
                    ex["source"] = source_tag
                existing["examples"].append(ex)
            else:
                existing["examples"].append({
                    "title": "Example",
                    "code": str(ex),
                    "context": "",
                    "source": source_tag,
                })

    # Union merge: pitfalls
    if override.get("pitfalls"):
        for pitfall in override["pitfalls"]:
            if isinstance(pitfall, dict):
                existing.setdefault("pitfalls", []).append(pitfall)
            else:
                existing.setdefault("pitfalls", []).append({
                    "description": pitfall,
                    "source": source_tag,
                })

    # Union merge: crossReferences (deduplicated)
    if override.get("crossReferences"):
        existing_refs = set(existing.get("crossReferences", []))
        for ref in override["crossReferences"]:
            existing_refs.add(ref)
        existing["crossReferences"] = sorted(existing_refs)

    return existing


def _load_phase4_prose(filepath: Path, strip_heading: bool = False) -> str:
    """Load a Phase 4 userDocs file as a flat prose string.

    If strip_heading is True, remove a leading '# ClassName' line
    (used for class-level Readme.md files).
    """
    if not filepath.is_file():
        return ""
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read().strip()
    if strip_heading and text.startswith("#"):
        # Remove the first line (heading) and strip leading whitespace
        lines = text.split("\n", 1)
        text = lines[1].strip() if len(lines) > 1 else ""
    return text


def run_merge():
    """Merge all phases into output/api_reference.json."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    output = {
        "version": "1.0",
        "generated": datetime.now(timezone.utc).isoformat(),
        "classes": {},
    }

    base_files = sorted(BASE_DIR.glob("*.json"))
    if not base_files:
        print("ERROR: No base JSON files found.")
        sys.exit(1)

    for json_path in base_files:
        with open(json_path, "r", encoding="utf-8") as f:
            base = json.load(f)

        class_name = base["className"]
        category = base.get("category", CATEGORY_MAP.get(class_name, "object"))

        # --- Phase 1 data ---
        p1_readme = {}
        p1_methods = {}
        p1_class_dir = PHASE1_DIR / class_name
        if p1_class_dir.is_dir():
            p1_readme = parse_readme_md(p1_class_dir / "Readme.md")
            p1_methods = parse_methods_md(p1_class_dir / "methods.md")

        # Case-insensitive method name lookup: lowercase -> canonical name
        method_name_map = {m.lower(): m for m in base.get("methods", {}).keys()}
        for m in p1_methods:
            method_name_map.setdefault(m.lower(), m)

        # --- Phase 2 data ---
        p2_methods = {}
        p2_class_dir = PHASE2_DIR / class_name
        if p2_class_dir.is_dir():
            for md_file in p2_class_dir.glob("*.md"):
                raw_name = md_file.stem
                method_name = method_name_map.get(raw_name.lower(), raw_name)
                p2_methods[method_name] = parse_method_override_md(md_file)

        # --- Phase 3 data ---
        p3_readme = {}
        p3_methods = {}
        p3_class_dir = PHASE3_DIR / class_name
        if p3_class_dir.is_dir():
            readme_path = p3_class_dir / "Readme.md"
            if readme_path.is_file():
                p3_readme = parse_readme_md(readme_path)
            for md_file in p3_class_dir.glob("*.md"):
                if md_file.name.lower() != "readme.md":
                    raw_name = md_file.stem
                    method_name = method_name_map.get(raw_name.lower(), raw_name)
                    p3_methods[method_name] = parse_method_override_md(md_file)

        # --- Phase 4 data (userDocs) ---
        # manual/ wins over auto/. Files are flat prose (parsed by
        # _load_phase4_prose which strips an optional # heading).
        p4_class_userdocs = None
        p4_class_override = False
        p4_method_userdocs = {}  # method_name -> (prose, is_override)

        # Class-level Readme.md
        manual_readme = PHASE4_MANUAL_DIR / class_name / "Readme.md"
        auto_readme = PHASE4_AUTO_DIR / class_name / "Readme.md"
        if manual_readme.is_file():
            p4_class_userdocs = _load_phase4_prose(manual_readme, strip_heading=True)
            p4_class_override = True
        elif auto_readme.is_file():
            p4_class_userdocs = _load_phase4_prose(auto_readme, strip_heading=True)

        # Method-level files
        for phase4_dir, is_override in ((PHASE4_MANUAL_DIR, True), (PHASE4_AUTO_DIR, False)):
            method_dir = phase4_dir / class_name
            if not method_dir.is_dir():
                continue
            for md_file in method_dir.glob("*.md"):
                if md_file.name.lower() == "readme.md":
                    continue
                raw_name = md_file.stem
                canonical = method_name_map.get(raw_name.lower(), raw_name)
                # manual/ wins: if already set by manual pass, skip auto
                if canonical in p4_method_userdocs and not is_override:
                    continue
                prose = _load_phase4_prose(md_file, strip_heading=False)
                if prose:
                    p4_method_userdocs[canonical] = (prose, is_override)

        # --- Build class description ---
        # Start with Phase 1, override with Phase 3 (last-writer-wins)
        desc = build_class_description(base.get("description", ""), p1_readme, "auto")

        # Phase 3 overrides (last-writer-wins)
        for field in ("brief", "purpose", "details", "obtainedVia",
                       "codeExample", "alternatives", "relatedPreprocessors"):
            if field in p3_readme:
                desc[field] = p3_readme[field]

        # Phase 4: userDocs for class level
        desc["userDocs"] = p4_class_userdocs
        desc["userDocOverride"] = p4_class_override if p4_class_userdocs else False

        # --- Constants ---
        constants = build_constants(p1_readme, "auto")
        p3_constants = build_constants(p3_readme, "manual")
        constants.update(p3_constants)  # Last-writer-wins per constant

        # --- Dynamic Constants ---
        dyn_constants = build_dynamic_constants(p1_readme, "auto")
        p3_dyn = build_dynamic_constants(p3_readme, "manual")
        dyn_constants.update(p3_dyn)

        # --- Common Mistakes (union merge) ---
        common_mistakes = build_common_mistakes(p1_readme, "auto")
        common_mistakes.extend(build_common_mistakes(p3_readme, "manual"))

        # --- Methods ---
        methods_output = {}
        all_method_names = set(base.get("methods", {}).keys())
        all_method_names.update(p1_methods.keys())
        all_method_names.update(p2_methods.keys())
        all_method_names.update(p3_methods.keys())

        for method_name in sorted(all_method_names):
            base_method = base.get("methods", {}).get(method_name, {})
            p1_method = p1_methods.get(method_name, {})
            p2_method = p2_methods.get(method_name, {})
            p3_method = p3_methods.get(method_name, {})

            # Start with base + Phase 1
            entry = build_method_entry(base_method, p1_method, "auto")

            # Apply Phase 2 overrides
            if p2_method:
                entry = merge_method_entries(entry, p2_method, "project")

            # Apply Phase 3 overrides
            if p3_method:
                entry = merge_method_entries(entry, p3_method, "manual")

            # Phase 4: userDocs for method level
            if method_name in p4_method_userdocs:
                prose, is_override = p4_method_userdocs[method_name]
                entry["userDocs"] = prose
                entry["userDocOverride"] = is_override
            else:
                entry["userDocs"] = None
                entry["userDocOverride"] = False

            methods_output[method_name] = entry

        # --- Assemble class output ---
        output["classes"][class_name] = {
            "description": desc,
            "category": category,
            "constants": constants if constants else {},
            "dynamicConstants": dyn_constants if dyn_constants else {},
            "commonMistakes": common_mistakes if common_mistakes else [],
            "methods": methods_output,
        }

    # Write output
    output_path = OUTPUT_DIR / "api_reference.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    class_count = len(output["classes"])
    method_count = sum(
        len(c["methods"]) for c in output["classes"].values()
    )
    print(f"Merge complete:")
    print(f"  Classes: {class_count}")
    print(f"  Total methods: {method_count}")
    print(f"  Output: {output_path}")


# ===================================================================
# Preview
# ===================================================================

PREVIEW_DIR = OUTPUT_DIR / "preview"


def md_inline(text: str) -> str:
    """HTML-escape text, then convert markdown `backtick` spans to <code> tags."""
    text = html_escape(text)
    text = re.sub(r"`([^`]+)`", r"<code>\1</code>", text)
    return text


def _source_badge(is_override: bool) -> str:
    """Return an HTML badge indicating auto or manual source."""
    if is_override:
        return '<span class="tag tag-manual">manual</span>'
    return '<span class="tag tag-auto">auto</span>'


def generate_class_html(class_name: str, c: dict, mode: str = "review") -> str:
    """Generate a full HTML preview page for one class.

    mode="review" -- shows raw C++ analysis (brief/purpose/details + description)
    mode="web"    -- shows userDocs content with auto/manual badges
    """
    is_web = mode == "web"
    desc = c.get("description", {})
    methods = c.get("methods", {})

    # --- Collect sidebar section IDs ---
    sidebar_sections = []
    if is_web:
        if desc.get("userDocs"):
            sidebar_sections.append(("overview", "Overview"))
    else:
        if desc.get("purpose"):
            sidebar_sections.append(("overview", "Overview"))
        if desc.get("details"):
            sidebar_sections.append(("details", "Details"))
    if desc.get("codeExample"):
        sidebar_sections.append(("usage-example", "Usage Example"))
    if c.get("commonMistakes"):
        sidebar_sections.append(("common-mistakes", "Common Mistakes"))
    if not is_web and desc.get("relatedPreprocessors"):
        sidebar_sections.append(("preprocessors", "Preprocessors"))

    # --- Sidebar HTML ---
    sidebar = f'<div class="sidebar">\n'
    sidebar += f'<div class="sidebar-title">{class_name}</div>\n'
    if is_web:
        sidebar += '<div class="sidebar-mode mode-web">userDocs</div>\n'
    else:
        sidebar += '<div class="sidebar-mode mode-review">review</div>\n'
    for sid, label in sidebar_sections:
        sidebar += f'<a class="sidebar-link" href="#{sid}">{label}</a>\n'
    if methods:
        sidebar += '<div class="sidebar-divider">Methods</div>\n'
        for name in methods:
            sidebar += f'<a class="sidebar-link sidebar-method" href="#{name}">{name}</a>\n'
    sidebar += '</div>\n'

    # --- Build all section IDs for IntersectionObserver ---
    all_ids = [sid for sid, _ in sidebar_sections] + list(methods.keys())
    ids_js = ", ".join(f'"{i}"' for i in all_ids)

    # --- Main content ---
    main = '<div class="main">\n'

    # Header
    mode_label = "userDocs" if is_web else "review"
    main += f'<h1>{class_name} <span class="category">{md_inline(c.get("category", ""))}</span></h1>\n'
    if desc.get("brief"):
        main += f'<p class="brief">{md_inline(desc["brief"])}</p>\n'
    if not is_web and desc.get("obtainedVia"):
        main += f'<p><strong>Obtained via:</strong> {md_inline(desc["obtainedVia"])}</p>\n'

    # Class-level prose
    if is_web:
        if desc.get("userDocs"):
            badge = _source_badge(desc.get("userDocOverride", False))
            main += f'<h2 id="overview">Overview {badge}</h2>\n'
            for para in desc["userDocs"].split("\n\n"):
                para = para.strip()
                if para:
                    main += f"<p>{md_inline(para)}</p>\n"
    else:
        # Review mode: show purpose + details
        if desc.get("purpose"):
            main += '<h2 id="overview">Overview</h2>\n'
            main += f'<p>{md_inline(desc["purpose"])}</p>\n'
        if desc.get("details"):
            main += '<h2 id="details">Details</h2>\n'
            for para in desc["details"].split("\n\n"):
                para = para.strip()
                if para:
                    main += f"<p>{md_inline(para)}</p>\n"

    # Code example (both modes)
    if desc.get("codeExample"):
        main += '<h2 id="usage-example">Usage Example</h2>\n'
        main += f'<pre><code class="language-javascript">{html_escape(desc["codeExample"])}</code></pre>\n'

    # Common mistakes (both modes)
    if c.get("commonMistakes"):
        main += '<h2 id="common-mistakes">Common Mistakes</h2>\n'
        for m in c["commonMistakes"]:
            main += (
                '<div class="mistake">'
                f'<strong>Wrong:</strong> {md_inline(m["wrong"])}<br>'
                f'<strong>Right:</strong> {md_inline(m["right"])}<br>'
                f'<em>{md_inline(m["explanation"])}</em></div>\n'
            )

    # Related preprocessors (review mode only)
    if not is_web and desc.get("relatedPreprocessors"):
        main += '<h2 id="preprocessors">Related Preprocessors</h2>\n'
        main += "<p>" + ", ".join(
            f"<code>{p}</code>" for p in desc["relatedPreprocessors"]
        ) + "</p>\n"

    # Methods
    if methods:
        main += '<h2 id="methods-heading">Methods</h2>\n'

        for name, m in methods.items():
            rt_tag = ""
            if m.get("realtimeSafe") is True:
                rt_tag = '<span class="tag tag-true">realtime safe</span>'
            elif m.get("realtimeSafe") is False:
                rt_tag = '<span class="tag tag-false">not realtime safe</span>'

            main += f'<div class="method-card" id="{name}">\n'
            main += f"<h3>{name} {rt_tag}</h3>\n"

            if m.get("signature"):
                main += f'<div class="signature">{html_escape(m["signature"])}</div>\n'

            # Method description: web mode uses userDocs, review uses description
            if is_web and m.get("userDocs"):
                badge = _source_badge(m.get("userDocOverride", False))
                main += f'<p>{md_inline(m["userDocs"])} {badge}</p>\n'
            else:
                main += f'<p>{md_inline(m.get("description", ""))}</p>\n'

            # Params (both modes)
            if m.get("parameters"):
                main += "<table><tr><th>Parameter</th><th>Type</th><th>Description</th></tr>\n"
                for p in m["parameters"]:
                    main += (
                        f'<tr><td><code>{html_escape(p.get("name", ""))}</code></td>'
                        f'<td><code>{html_escape(p.get("type", ""))}</code></td>'
                        f'<td>{md_inline(p.get("description", ""))}</td></tr>\n'
                    )
                main += "</table>\n"

            # Pitfalls (both modes)
            for p in m.get("pitfalls", []):
                main += f'<div class="pitfall">{md_inline(p.get("description", ""))}</div>\n'

            # Examples (both modes)
            for ex in m.get("examples", []):
                main += f'<pre><code class="language-javascript">{html_escape(ex.get("code", ""))}</code></pre>\n'

            # Cross refs (both modes)
            if m.get("crossReferences"):
                refs = ", ".join(
                    f'<a href="#{r.split(".")[-1]}">{r}</a>'
                    for r in m["crossReferences"]
                )
                main += f"<p><strong>See also:</strong> {refs}</p>\n"

            main += "</div>\n"

    main += "</div>\n"

    # --- Assemble full HTML ---
    html = f"""<!DOCTYPE html>
<html><head>
<meta charset="utf-8">
<title>{class_name} ({mode_label}) - HISE Scripting API</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
<style>
* {{ box-sizing: border-box; }}
body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; margin: 0; padding: 0; color: #e0e0e0; background: #1e1e1e; line-height: 1.6; }}
code, pre, .signature {{ font-family: "JetBrains Mono", Consolas, "Fira Code", monospace; }}

/* Sidebar */
.sidebar {{ position: fixed; top: 0; left: 0; width: 220px; height: 100vh; background: #1a1a1a; border-right: 1px solid #333; padding: 20px 0; overflow-y: auto; }}
.sidebar-title {{ font-size: 1.1em; font-weight: 700; color: #fff; padding: 0 16px 12px; border-bottom: 1px solid #333; margin-bottom: 8px; }}
.sidebar-link {{ display: block; padding: 4px 16px; color: #888; text-decoration: none; font-size: 0.85em; transition: color 0.15s, background 0.15s; }}
.sidebar-link:hover {{ color: #ddd; background: #252525; }}
.sidebar-link.active {{ color: #66d9ef; background: #252530; border-right: 2px solid #66d9ef; }}
.sidebar-divider {{ font-size: 0.75em; color: #555; text-transform: uppercase; letter-spacing: 0.08em; padding: 12px 16px 4px; }}
.sidebar-method {{ font-family: "JetBrains Mono", Consolas, monospace; font-size: 0.8em; }}

/* Main content */
.main {{ margin-left: 220px; max-width: 1040px; padding: 40px 40px 80px; }}
h1 {{ color: #fff; border-bottom: 2px solid #444; padding-bottom: 8px; }}
h2 {{ color: #ddd; margin-top: 40px; border-bottom: 1px solid #333; padding-bottom: 4px; }}
h3 {{ color: #ccc; margin-top: 24px; }}
.brief {{ font-size: 1.1em; color: #aaa; margin-bottom: 20px; }}
.category {{ display: inline-block; background: #333; color: #aaa; padding: 2px 10px; border-radius: 4px; font-size: 0.5em; margin-left: 12px; vertical-align: middle; }}
code {{ background: #2d2d2d; padding: 2px 6px; border-radius: 3px; font-size: 0.9em; color: #e6db74; }}
pre {{ background: #2d2d2d; padding: 16px; border-radius: 6px; overflow-x: auto; border: 1px solid #333; }}
pre code {{ background: none; padding: 0; }}

/* Signature emphasis */
.signature {{ background: #151518; border-left: 3px solid #66d9ef; padding: 10px 16px; border-radius: 0 6px 6px 0; font-size: 1.05em; color: #66d9ef; margin: 8px 0 16px; }}

/* Tables */
table {{ border-collapse: collapse; width: 100%; margin: 12px 0; }}
th, td {{ border: 1px solid #444; padding: 8px 12px; text-align: left; }}
th {{ background: #2a2a2a; color: #aaa; font-weight: 600; }}
td {{ color: #ccc; }}

/* Tags */
.tag {{ display: inline-block; padding: 1px 8px; border-radius: 3px; font-size: 0.75em; margin-left: 6px; }}
.tag-true {{ background: #1a3a1a; color: #4ec94e; }}
.tag-false {{ background: #3a1a1a; color: #c94e4e; }}
.tag-auto {{ background: #1a2a3a; color: #5ba8d9; }}
.tag-manual {{ background: #2a1a3a; color: #b07ad9; }}

/* Sidebar mode indicator */
.sidebar-mode {{ font-size: 0.7em; text-transform: uppercase; letter-spacing: 0.1em; padding: 4px 16px 8px; border-bottom: 1px solid #333; margin-bottom: 4px; }}
.mode-review {{ color: #888; }}
.mode-web {{ color: #5ba8d9; }}

/* Callout boxes */
.pitfall {{ background: #332b00; border-left: 3px solid #997a00; padding: 8px 12px; margin: 8px 0; border-radius: 0 4px 4px 0; color: #ccc; }}
.mistake {{ background: #2d1a1a; border-left: 3px solid #994444; padding: 8px 12px; margin: 8px 0; border-radius: 0 4px 4px 0; }}

/* Method cards */
.method-card {{ margin: 24px 0; padding: 16px; background: #252525; border-radius: 8px; border: 1px solid #333; }}

a {{ color: #66d9ef; }}
</style>
</head>
<body>
{sidebar}
{main}
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-javascript.min.js"></script>
<script>
// Highlight active sidebar link on scroll
(function() {{
    const ids = [{ids_js}];
    const links = {{}};
    ids.forEach(id => {{
        const el = document.querySelector('.sidebar-link[href="#' + id + '"]');
        if (el) links[id] = el;
    }});
    const observer = new IntersectionObserver(entries => {{
        entries.forEach(entry => {{
            if (entry.isIntersecting && links[entry.target.id]) {{
                Object.values(links).forEach(l => l.classList.remove('active'));
                links[entry.target.id].classList.add('active');
            }}
        }});
    }}, {{ rootMargin: '0px 0px -70% 0px' }});
    ids.forEach(id => {{
        const el = document.getElementById(id);
        if (el) observer.observe(el);
    }});
}})();
</script>
</body></html>"""

    return html


def run_preview(class_filter: str = None):
    """Generate HTML preview pages from api_reference.json."""
    json_path = OUTPUT_DIR / "api_reference.json"
    if not json_path.is_file():
        print("ERROR: No api_reference.json found. Run 'merge' first.")
        sys.exit(1)

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    PREVIEW_DIR.mkdir(parents=True, exist_ok=True)

    classes = data.get("classes", {})
    if class_filter:
        # Case-insensitive lookup
        name_map = {k.lower(): k for k in classes}
        canonical = name_map.get(class_filter.lower())
        if not canonical:
            print(f"ERROR: Class '{class_filter}' not found in api_reference.json.")
            sys.exit(1)
        targets = {canonical: classes[canonical]}
    else:
        # Only generate for classes that have enrichment data (brief != base description)
        targets = {}
        for name, c in classes.items():
            p1_dir = PHASE1_DIR / name
            if p1_dir.is_dir():
                targets[name] = c
        if not targets:
            print("No enriched classes found. Run Phase 1 for at least one class.")
            sys.exit(1)

    page_count = 0
    for name, c in targets.items():
        # Always generate the review page (raw analysis)
        html_review = generate_class_html(name, c, mode="review")
        out_review = PREVIEW_DIR / f"{name}_review.html"
        with open(out_review, "w", encoding="utf-8") as f:
            f.write(html_review)
        print(f"  {out_review}")
        page_count += 1

        # Generate web page (userDocs) if any userDocs exist
        has_userdocs = (
            c.get("description", {}).get("userDocs") is not None
            or any(
                m.get("userDocs") is not None
                for m in c.get("methods", {}).values()
            )
        )
        if has_userdocs:
            html_web = generate_class_html(name, c, mode="web")
            out_web = PREVIEW_DIR / f"{name}.html"
            with open(out_web, "w", encoding="utf-8") as f:
                f.write(html_web)
            print(f"  {out_web}")
            page_count += 1

    print(f"Preview: {page_count} page(s) generated.")


# ===================================================================
# CLI
# ===================================================================

def main():
    parser = argparse.ArgumentParser(
        description="API Enrichment Pipeline CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    subparsers = parser.add_subparsers(dest="command", help="Subcommand to run")

    subparsers.add_parser(
        "phase0",
        help="Parse Doxygen XML → base JSON (mechanical, no AI)",
    )
    subparsers.add_parser(
        "prepare",
        help="Print worklist of unscanned classes/methods",
    )
    subparsers.add_parser(
        "merge",
        help="Merge all phases → output/api_reference.json",
    )
    preview_parser = subparsers.add_parser(
        "preview",
        help="Generate HTML preview pages from merged JSON",
    )
    preview_parser.add_argument(
        "classname", nargs="?", default=None,
        help="Class name to preview (default: all enriched classes)",
    )

    args = parser.parse_args()

    if args.command == "phase0":
        run_phase0()
    elif args.command == "prepare":
        run_prepare()
    elif args.command == "merge":
        run_merge()
    elif args.command == "preview":
        run_preview(args.classname)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
