#!/usr/bin/env python3
"""
API Enrichment Pipeline CLI

Produces a comprehensive api_reference.json from Doxygen XML, AI-generated
analysis, project examples, and manual overrides.

Subcommands:
    phase0   - Parse Doxygen XML → base JSON (mechanical)
    prepare  - Print worklist of unscanned classes/methods
    merge    - Merge all phases → output/api_reference.json

Usage:
    python api_enrich.py phase0
    python api_enrich.py prepare
    python api_enrich.py merge
"""

import argparse
import json
import os
import re
import sys
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
from pathlib import Path

# ---------------------------------------------------------------------------
# Paths (relative to this script's directory)
# ---------------------------------------------------------------------------

SCRIPT_DIR = Path(__file__).resolve().parent
XML_SELECTION_DIR = SCRIPT_DIR / "xml" / "selection"
ENRICHMENT_DIR = SCRIPT_DIR / "enrichment"
BASE_DIR = ENRICHMENT_DIR / "base"
PHASE1_DIR = ENRICHMENT_DIR / "phase1"
PHASE2_DIR = ENRICHMENT_DIR / "phase2"
PHASE3_DIR = ENRICHMENT_DIR / "phase3"
OUTPUT_DIR = ENRICHMENT_DIR / "output"
SCANNED_FILE = ENRICHMENT_DIR / "phase1_scanned.txt"

# ---------------------------------------------------------------------------
# Category mapping: friendly class name → category
# Derived from batchCreate.bat rename mappings.
# ---------------------------------------------------------------------------

CATEGORY_MAP = {
    # namespace — global API namespaces
    "Array": "namespace",
    "Colours": "namespace",
    "Console": "namespace",
    "Content": "namespace",
    "Date": "namespace",
    "Engine": "namespace",
    "FileSystem": "namespace",
    "Math": "namespace",
    "Message": "namespace",
    "ModuleIds": "namespace",
    "Sampler": "namespace",
    "Server": "namespace",
    "Settings": "namespace",
    "String": "namespace",
    "Synth": "namespace",
    "Threads": "namespace",
    "TransportHandler": "namespace",

    # object — instances obtained via factory methods or module references
    "AudioFile": "object",
    "AudioSampleProcessor": "object",
    "BackgroundTask": "object",
    "BeatportManager": "object",
    "Broadcaster": "object",
    "Buffer": "object",
    "Builder": "object",
    "ChildSynth": "object",
    "ComplexGroupManager": "object",
    "ContainerChild": "object",
    "DisplayBuffer": "object",
    "DisplayBufferSource": "object",
    "Download": "object",
    "DspModule": "object",
    "Effect": "object",
    "ErrorHandler": "object",
    "Expansion": "object",
    "ExpansionHandler": "object",
    "FFT": "object",
    "File": "object",
    "FixObjectArray": "object",
    "FixObjectFactory": "object",
    "FixObjectStack": "object",
    "GlobalCable": "object",
    "GlobalRoutingManager": "object",
    "Graphics": "object",
    "LorisManager": "object",
    "MacroHandler": "object",
    "MarkdownRenderer": "object",
    "MessageHolder": "object",
    "MidiAutomationHandler": "object",
    "MidiList": "object",
    "MidiPlayer": "object",
    "MidiProcessor": "object",
    "Modifiers": "object",
    "Modulator": "object",
    "NeuralNetwork": "object",
    "Path": "object",
    "PresetStorage": "object",
    "Rectangle": "object",
    "RoutingMatrix": "object",
    "Sample": "object",
    "ScriptLookAndFeel": "object",
    "ScriptModulationMatrix": "object",
    "ScriptShader": "object",
    "SliderPackData": "object",
    "SliderPackProcessor": "object",
    "SlotFX": "object",
    "Table": "object",
    "TableProcessor": "object",
    "ThreadSafeStorage": "object",
    "Timer": "object",
    "Unlocker": "object",
    "UnorderedStack": "object",
    "UserPresetHandler": "object",
    "WavetableController": "object",

    # component — UI components created via Content.addX()
    "ScriptAudioWaveform": "component",
    "ScriptButton": "component",
    "ScriptComboBox": "component",
    "ScriptDynamicContainer": "component",
    "ScriptFloatingTile": "component",
    "ScriptImage": "component",
    "ScriptLabel": "component",
    "ScriptMultipageDialog": "component",
    "ScriptPanel": "component",
    "ScriptSlider": "component",
    "ScriptSliderPack": "component",
    "ScriptTable": "component",
    "ScriptWebView": "component",
    "ScriptedViewport": "component",

    # component — not generated by last Doxygen run but present in batchCreate.bat
    "ModulatorMeter": "component",
    "ScriptedPlotter": "component",

    # scriptnode — ScriptNode DSP classes
    "Connection": "scriptnode",
    "DspNetwork": "scriptnode",
    "NetworkTest": "scriptnode",
    "Node": "scriptnode",
    "Parameter": "scriptnode",
}

# ---------------------------------------------------------------------------
# Filtering: infrastructure method exclusion
# ---------------------------------------------------------------------------

# Method names that are always infrastructure, even if they have descriptions
INFRASTRUCTURE_METHODS = {
    "getObjectName", "getClassName", "allowIllegalCallsOnAudioThread",
    "setDebugLocation", "timerCallback", "allowRefCount",
    "isControlCallbackPending",       # REST API internal (ScriptComponent)
    "updateContentPropertyInternal",  # Internal property update (ScriptComponent)
}

# C++ type substrings that indicate a non-scriptable (infrastructure) method.
# If any parameter type or the return type contains one of these, the method
# is excluded from the scripting API surface.
NON_SCRIPTABLE_TYPE_PATTERNS = [
    "Component",
    "MouseEvent",
    "HiseJavascriptEngine",
    "ValueTree",
    "DebugableObjectBase",
    "NotificationType",
    "KeyPress",
    "ZLevelListener",
    "ProfileCollection",
    "WeakCallbackHolder",
    "SubComponentListener",
    "NativeFunctionArgs",
    "Identifier",
    "Location",
]

# ---------------------------------------------------------------------------
# C++ type normalization for Phase 0 output
# ---------------------------------------------------------------------------

TYPE_NORMALIZATIONS = {
    "const String &": "String",
    "const String&": "String",
    "String &": "String",
    "String&": "String",
    "const var &": "var",
    "const var&": "var",
    "var &": "var",
    "var&": "var",
}


def normalize_cpp_type(raw_type: str) -> str:
    """Normalize a C++ type string for the base JSON output."""
    t = raw_type.strip()
    # Apply exact normalizations first
    if t in TYPE_NORMALIZATIONS:
        return TYPE_NORMALIZATIONS[t]
    # Strip leading 'const ' and trailing ' &' / '&' for remaining types
    t = re.sub(r"^const\s+", "", t)
    t = re.sub(r"\s*&$", "", t)
    return t.strip()


def contains_non_scriptable_type(type_str: str) -> bool:
    """Check if a type string contains a non-scriptable C++ type."""
    for pattern in NON_SCRIPTABLE_TYPE_PATTERNS:
        if pattern in type_str:
            return True
    return False


# ---------------------------------------------------------------------------
# XML text extraction helpers
# ---------------------------------------------------------------------------

def get_text_content(element) -> str:
    """Recursively extract all text from an XML element and its children."""
    if element is None:
        return ""
    parts = []
    if element.text:
        parts.append(element.text)
    for child in element:
        parts.append(get_text_content(child))
        if child.tail:
            parts.append(child.tail)
    return "".join(parts).strip()


def get_description(memberdef) -> str:
    """Extract the description text from a memberdef's detaileddescription."""
    detailed = memberdef.find("detaileddescription")
    if detailed is None:
        return ""
    return get_text_content(detailed)


# ===================================================================
# PHASE 0: Doxygen XML → Base JSON
# ===================================================================

def run_phase0():
    """Parse all Doxygen XML files in xml/selection/ and produce base JSON."""
    if not XML_SELECTION_DIR.is_dir():
        print(f"ERROR: XML selection directory not found: {XML_SELECTION_DIR}")
        sys.exit(1)

    BASE_DIR.mkdir(parents=True, exist_ok=True)

    xml_files = sorted(XML_SELECTION_DIR.glob("*.xml"))
    if not xml_files:
        print(f"ERROR: No XML files found in {XML_SELECTION_DIR}")
        sys.exit(1)

    total_classes = 0
    total_methods = 0
    skipped_infra = 0

    for xml_path in xml_files:
        class_name = xml_path.stem  # e.g., "Console" from "Console.xml"

        # Skip files not in our category map (shouldn't happen, but be safe)
        if class_name not in CATEGORY_MAP:
            print(f"  WARNING: {class_name} not in category map, skipping")
            continue

        try:
            tree = ET.parse(xml_path)
        except ET.ParseError:
            # Some Doxygen XML files contain invalid characters (e.g., degree
            # symbol in Math.xml). Re-read as bytes, strip non-XML chars, retry.
            try:
                raw = xml_path.read_bytes()
                # Strip bytes outside the valid XML 1.0 character range
                cleaned = bytes(b for b in raw if b == 0x09 or b == 0x0A
                                or b == 0x0D or 0x20 <= b < 0x7F)
                tree = ET.ElementTree(ET.fromstring(cleaned))
            except Exception as e2:
                print(f"  ERROR: Failed to parse {xml_path} even after "
                      f"cleaning: {e2}")
                continue

        root = tree.getroot()
        compounddef = root.find("compounddef")
        if compounddef is None:
            print(f"  WARNING: No compounddef in {xml_path}, skipping")
            continue

        # Class-level description
        class_desc = get_description(compounddef)

        # Collect public methods
        methods = {}
        for sectiondef in compounddef.findall("sectiondef"):
            kind = sectiondef.get("kind", "")
            if kind not in ("public-func", "public-static-func"):
                continue

            for memberdef in sectiondef.findall("memberdef"):
                if memberdef.get("kind") != "function":
                    continue

                name = get_text_content(memberdef.find("name"))
                return_type_raw = get_text_content(memberdef.find("type"))

                # --- Exclusion filters ---

                # 1. Skip constructors (empty return type) and destructors
                if not return_type_raw or name.startswith("~"):
                    continue

                # 2. Skip known infrastructure method names
                if name in INFRASTRUCTURE_METHODS:
                    skipped_infra += 1
                    continue

                # 3. Skip methods with empty descriptions
                desc = get_description(memberdef)
                if not desc:
                    skipped_infra += 1
                    continue

                # 4. Skip methods with non-scriptable types in return or params
                if contains_non_scriptable_type(return_type_raw):
                    skipped_infra += 1
                    continue

                param_has_non_scriptable = False
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    if contains_non_scriptable_type(param_type_raw):
                        param_has_non_scriptable = True
                        break
                if param_has_non_scriptable:
                    skipped_infra += 1
                    continue

                # --- Extract method data ---

                return_type = normalize_cpp_type(return_type_raw)

                parameters = []
                for param in memberdef.findall("param"):
                    param_type_raw = get_text_content(param.find("type"))
                    param_name_el = param.find("declname")
                    param_name = get_text_content(param_name_el) if param_name_el is not None else ""
                    param_type = normalize_cpp_type(param_type_raw)

                    if param_name:  # Skip unnamed parameters
                        parameters.append({
                            "name": param_name,
                            "type": param_type,
                        })

                # Build signature string
                param_strs = [f"{p['type']} {p['name']}" for p in parameters]
                signature = f"{return_type} {name}({', '.join(param_strs)})"

                methods[name] = {
                    "signature": signature,
                    "returnType": return_type,
                    "description": desc,
                    "parameters": parameters,
                }

                total_methods += 1

        # Write base JSON
        base_json = {
            "className": class_name,
            "category": CATEGORY_MAP[class_name],
            "description": class_desc,
            "methods": methods,
        }

        output_path = BASE_DIR / f"{class_name}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(base_json, f, indent=2, ensure_ascii=False)

        total_classes += 1

    print(f"Phase 0 complete:")
    print(f"  Classes processed: {total_classes}")
    print(f"  Methods extracted: {total_methods}")
    print(f"  Infrastructure methods filtered: {skipped_infra}")
    print(f"  Output: {BASE_DIR}")


# ===================================================================
# PREPARE: Print worklist of unscanned classes/methods
# ===================================================================

def run_prepare():
    """Read base JSON and scanned manifest, print unscanned worklist."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    # Read scanned manifest
    scanned = set()
    if SCANNED_FILE.is_file():
        with open(SCANNED_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    scanned.add(line)

    # Read all base JSON files
    total_remaining = 0
    total_scanned = 0
    worklist = []

    for json_path in sorted(BASE_DIR.glob("*.json")):
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        class_name = data["className"]
        methods = data.get("methods", {})

        unscanned_methods = []
        for method_name in sorted(methods.keys()):
            key = f"{class_name}.{method_name}"
            if key in scanned:
                total_scanned += 1
            else:
                unscanned_methods.append(method_name)
                total_remaining += 1

        if unscanned_methods:
            worklist.append((class_name, data.get("category", "?"), unscanned_methods))

    if not worklist:
        print("All methods have been scanned. Nothing to do.")
        print(f"  Total scanned: {total_scanned}")
        return

    print(f"Worklist: {total_remaining} methods remaining across {len(worklist)} classes")
    print(f"Already scanned: {total_scanned}")
    print()

    for class_name, category, methods in worklist:
        print(f"  {class_name} [{category}] — {len(methods)} methods:")
        for m in methods:
            print(f"    - {m}")
        print()


# ===================================================================
# MERGE: Combine all phases → output/api_reference.json
# ===================================================================

# --- Markdown parsing utilities ---

def parse_readme_md(filepath: Path) -> dict:
    """Parse a Phase 1/3 Readme.md into a structured dict.

    Expected sections: Brief, Purpose, Details, obtainedVia, Constants,
    Dynamic Constants, Common Mistakes, codeExample, Alternatives,
    Related Preprocessors.
    """
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    result = {}

    # Extract sections by ## headings
    sections = split_by_headings(content, level=2)

    if "Brief" in sections:
        result["brief"] = sections["Brief"].strip()

    if "Purpose" in sections:
        result["purpose"] = sections["Purpose"].strip()

    if "Details" in sections:
        details = sections["Details"].strip()
        if details:
            result["details"] = details

    if "obtainedVia" in sections:
        text = sections["obtainedVia"].strip()
        # Strip backticks if wrapped
        text = text.strip("`")
        result["obtainedVia"] = text

    if "codeExample" in sections:
        result["codeExample"] = extract_code_block(sections["codeExample"])

    if "Alternatives" in sections:
        text = sections["Alternatives"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            result["alternatives"] = text

    if "Related Preprocessors" in sections:
        text = sections["Related Preprocessors"].strip()
        if text.lower() not in ("none.", "none", "n/a", ""):
            # Parse comma-separated or backtick-wrapped preprocessor names
            preprocessors = re.findall(r"`([^`]+)`", text)
            if not preprocessors:
                preprocessors = [p.strip() for p in text.split(",") if p.strip()]
            if preprocessors:
                result["relatedPreprocessors"] = preprocessors

    if "Constants" in sections:
        result["constants"] = parse_markdown_table(sections["Constants"])

    if "Dynamic Constants" in sections:
        result["dynamicConstants"] = parse_markdown_table(sections["Dynamic Constants"])

    if "Common Mistakes" in sections:
        result["commonMistakes"] = parse_markdown_table(sections["Common Mistakes"])

    return result


def parse_methods_md(filepath: Path) -> dict:
    """Parse a Phase 1 methods.md into a dict of method_name → method_data."""
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    methods = {}
    # Split by ## headings (level 2) — each is a method
    method_sections = split_by_headings(content, level=2)

    for method_name, body in method_sections.items():
        method_data = parse_single_method(body)
        if method_data:
            methods[method_name] = method_data

    return methods


def parse_method_override_md(filepath: Path) -> dict:
    """Parse a Phase 2/3 method override file (single method)."""
    if not filepath.is_file():
        return {}

    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    return parse_single_method(content)


def parse_single_method(body: str) -> dict:
    """Parse a single method's markdown body into structured data."""
    result = {}

    # Extract bold-prefixed fields
    sig_match = re.search(r"\*\*Signature:\*\*\s*`([^`]+)`", body)
    if sig_match:
        result["signature"] = sig_match.group(1)

    rt_match = re.search(r"\*\*Return Type:\*\*\s*`?([^`\n]+)`?", body)
    if rt_match:
        result["returnType"] = rt_match.group(1).strip()

    rts_match = re.search(r"\*\*Realtime Safe:\*\*\s*(\S+)", body)
    if rts_match:
        val = rts_match.group(1).strip().lower()
        if val == "true":
            result["realtimeSafe"] = True
        elif val == "false":
            result["realtimeSafe"] = False
        else:
            result["realtimeSafe"] = None

    # Description
    desc_match = re.search(
        r"\*\*Description:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if desc_match:
        result["description"] = desc_match.group(1).strip()

    # Parameters table
    params_match = re.search(
        r"\*\*Parameters:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if params_match:
        params_text = params_match.group(1)
        params = parse_parameter_table(params_text)
        if params:
            result["parameters"] = params

    # Pitfalls
    pitfalls_match = re.search(
        r"\*\*Pitfalls:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if pitfalls_match:
        pitfalls_text = pitfalls_match.group(1)
        pitfalls = parse_bullet_list(pitfalls_text)
        if pitfalls:
            result["pitfalls"] = pitfalls

    # Cross References
    xref_match = re.search(
        r"\*\*Cross References:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if xref_match:
        xref_text = xref_match.group(1)
        xrefs = []
        for line in xref_text.strip().splitlines():
            line = line.strip().lstrip("-").strip()
            # Remove backticks
            line = line.strip("`")
            if line:
                xrefs.append(line)
        if xrefs:
            result["crossReferences"] = xrefs

    # Example(s)
    example_match = re.search(
        r"\*\*Example(?:s)?:\*\*\s*\n(.*?)(?=\n\*\*|\n##|\Z)",
        body, re.DOTALL
    )
    if example_match:
        examples = parse_examples(example_match.group(1))
        if examples:
            result["examples"] = examples

    return result


# --- Markdown parsing helpers ---

def split_by_headings(content: str, level: int = 2) -> dict:
    """Split markdown content by headings of a given level.
    Returns dict of heading_text → body_text.
    """
    prefix = "#" * level
    pattern = rf"^{prefix}\s+(.+)$"
    sections = {}
    current_heading = None
    current_lines = []

    for line in content.splitlines():
        match = re.match(pattern, line)
        if match:
            if current_heading is not None:
                sections[current_heading] = "\n".join(current_lines)
            current_heading = match.group(1).strip()
            current_lines = []
        elif current_heading is not None:
            current_lines.append(line)

    if current_heading is not None:
        sections[current_heading] = "\n".join(current_lines)

    return sections


def extract_code_block(text: str) -> str:
    """Extract the content of the first fenced code block."""
    match = re.search(r"```\w*\n(.*?)```", text, re.DOTALL)
    if match:
        return match.group(1).strip()
    # Fall back to the raw text
    return text.strip()


def parse_markdown_table(text: str) -> list:
    """Parse a pipe-delimited markdown table into a list of dicts.
    First row is headers, second row is separator, rest are data.
    """
    lines = [l.strip() for l in text.strip().splitlines() if l.strip()]
    # Find table lines (contain |)
    table_lines = [l for l in lines if "|" in l]
    if len(table_lines) < 3:
        return []

    # Parse header
    headers = [h.strip() for h in table_lines[0].split("|") if h.strip()]

    # Skip separator (table_lines[1])
    rows = []
    for line in table_lines[2:]:
        cells = [c.strip() for c in line.split("|") if c.strip()]
        if len(cells) >= len(headers):
            row = {}
            for i, header in enumerate(headers):
                row[header] = cells[i] if i < len(cells) else ""
            rows.append(row)

    return rows


def parse_parameter_table(text: str) -> list:
    """Parse a parameter table from method markdown."""
    rows = parse_markdown_table(text)
    params = []
    for row in rows:
        param = {
            "name": row.get("Name", ""),
            "type": row.get("Type", ""),
            "forcedType": row.get("Forced", "").lower() in ("yes", "true"),
            "description": row.get("Description", ""),
        }
        constraints = row.get("Constraints", "")
        if constraints and constraints != "—":
            param["constraints"] = constraints
        params.append(param)
    return params


def parse_bullet_list(text: str) -> list:
    """Parse a markdown bullet list into a list of strings."""
    items = []
    for line in text.strip().splitlines():
        line = line.strip()
        if line.startswith("- "):
            items.append(line[2:].strip())
        elif line.startswith("* "):
            items.append(line[2:].strip())
    return items


def parse_examples(text: str) -> list:
    """Parse example sections from method markdown."""
    examples = []

    # Find all code blocks, optionally preceded by a title comment
    blocks = re.findall(
        r"(?:(?://\s*(.+)\n)|(?:###\s*(.+)\n))?```\w*\n(.*?)```",
        text, re.DOTALL
    )

    if blocks:
        for title_comment, title_heading, code in blocks:
            title = (title_heading or title_comment or "").strip()
            examples.append({
                "title": title or "Example",
                "code": code.strip(),
            })
    else:
        # Single code block without fence
        code = text.strip()
        if code:
            examples.append({
                "title": "Example",
                "code": code,
            })

    return examples


# --- Merge logic ---

def build_class_description(base_desc: str, readme_data: dict, source_tag: str) -> dict:
    """Build the class description object from base + readme data."""
    desc = {
        "brief": readme_data.get("brief"),
        "purpose": readme_data.get("purpose"),
        "details": readme_data.get("details"),
        "obtainedVia": readme_data.get("obtainedVia"),
        "codeExample": readme_data.get("codeExample"),
        "alternatives": readme_data.get("alternatives"),
        "relatedPreprocessors": readme_data.get("relatedPreprocessors", []),
        "userGuidePage": None,
    }

    # If no enrichment data, use the base description for brief/purpose
    if desc["brief"] is None and base_desc:
        desc["brief"] = base_desc
    if desc["purpose"] is None and base_desc:
        desc["purpose"] = base_desc

    return desc


def build_constants(readme_data: dict, source_tag: str) -> dict:
    """Build constants dict from parsed readme table rows."""
    constants = {}
    for row in readme_data.get("constants", []):
        name = row.get("Name", "")
        if not name:
            continue
        value = row.get("Value", "")
        # Try to parse numeric values
        try:
            value = int(value)
        except (ValueError, TypeError):
            try:
                value = float(value)
            except (ValueError, TypeError):
                pass

        constants[name] = {
            "value": value,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "group": row.get("Group", None) or None,
            "source": source_tag,
        }
    return constants


def build_dynamic_constants(readme_data: dict, source_tag: str) -> dict:
    """Build dynamic constants dict from parsed readme table rows."""
    dyn_constants = {}
    for row in readme_data.get("dynamicConstants", []):
        name = row.get("Name", "")
        if not name:
            continue
        dyn_constants[name] = {
            "value": None,
            "type": row.get("Type", ""),
            "description": row.get("Description", ""),
            "source": source_tag,
        }
    return dyn_constants


def build_common_mistakes(readme_data: dict, source_tag: str) -> list:
    """Build common mistakes list from parsed readme table rows."""
    mistakes = []
    for row in readme_data.get("commonMistakes", []):
        mistakes.append({
            "wrong": row.get("Wrong", ""),
            "right": row.get("Right", ""),
            "explanation": row.get("Explanation", ""),
            "source": source_tag,
        })
    return mistakes


def build_method_entry(base_method: dict, enriched: dict, source_tag: str) -> dict:
    """Build a full method entry by merging base data with enrichment."""
    entry = {
        "signature": enriched.get("signature", base_method.get("signature", "")),
        "returnType": enriched.get("returnType", base_method.get("returnType", "")),
        "description": enriched.get("description", base_method.get("description", "")),
        "parameters": [],
        "realtimeSafe": enriched.get("realtimeSafe"),
        "crossReferences": enriched.get("crossReferences", []),
        "pitfalls": [],
        "examples": [],
    }

    # Parameters: prefer enriched (has forcedType info), fall back to base
    if enriched.get("parameters"):
        entry["parameters"] = enriched["parameters"]
    else:
        # Convert base params (no forcedType info)
        for p in base_method.get("parameters", []):
            entry["parameters"].append({
                "name": p["name"],
                "type": p["type"],
                "forcedType": False,
                "description": p.get("description", ""),
            })

    # Pitfalls: tagged list items
    for pitfall_text in enriched.get("pitfalls", []):
        if isinstance(pitfall_text, dict):
            entry["pitfalls"].append(pitfall_text)
        else:
            entry["pitfalls"].append({
                "description": pitfall_text,
                "source": source_tag,
            })

    # Examples
    for ex in enriched.get("examples", []):
        if isinstance(ex, dict):
            if "source" not in ex:
                ex["source"] = source_tag
            entry["examples"].append(ex)
        else:
            entry["examples"].append({
                "title": "Example",
                "code": str(ex),
                "context": "",
                "source": source_tag,
            })

    return entry


def merge_method_entries(existing: dict, override: dict, source_tag: str) -> dict:
    """Merge an override method entry into an existing one.
    Last-writer-wins for most fields; union merge for pitfalls/crossRefs.
    """
    # Last-writer-wins fields
    if override.get("signature"):
        existing["signature"] = override["signature"]
    if override.get("returnType"):
        existing["returnType"] = override["returnType"]
    if override.get("description"):
        existing["description"] = override["description"]
    if override.get("parameters"):
        existing["parameters"] = override["parameters"]
    if "realtimeSafe" in override and override["realtimeSafe"] is not None:
        existing["realtimeSafe"] = override["realtimeSafe"]

    # Examples: last-writer-wins (entire array replaced)
    if override.get("examples"):
        existing["examples"] = []
        for ex in override["examples"]:
            if isinstance(ex, dict):
                if "source" not in ex:
                    ex["source"] = source_tag
                existing["examples"].append(ex)
            else:
                existing["examples"].append({
                    "title": "Example",
                    "code": str(ex),
                    "context": "",
                    "source": source_tag,
                })

    # Union merge: pitfalls
    if override.get("pitfalls"):
        for pitfall in override["pitfalls"]:
            if isinstance(pitfall, dict):
                existing.setdefault("pitfalls", []).append(pitfall)
            else:
                existing.setdefault("pitfalls", []).append({
                    "description": pitfall,
                    "source": source_tag,
                })

    # Union merge: crossReferences (deduplicated)
    if override.get("crossReferences"):
        existing_refs = set(existing.get("crossReferences", []))
        for ref in override["crossReferences"]:
            existing_refs.add(ref)
        existing["crossReferences"] = sorted(existing_refs)

    return existing


def run_merge():
    """Merge all phases into output/api_reference.json."""
    if not BASE_DIR.is_dir():
        print("ERROR: No base JSON found. Run 'phase0' first.")
        sys.exit(1)

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    output = {
        "version": "1.0",
        "generated": datetime.now(timezone.utc).isoformat(),
        "classes": {},
    }

    base_files = sorted(BASE_DIR.glob("*.json"))
    if not base_files:
        print("ERROR: No base JSON files found.")
        sys.exit(1)

    for json_path in base_files:
        with open(json_path, "r", encoding="utf-8") as f:
            base = json.load(f)

        class_name = base["className"]
        category = base.get("category", CATEGORY_MAP.get(class_name, "object"))

        # --- Phase 1 data ---
        p1_readme = {}
        p1_methods = {}
        p1_class_dir = PHASE1_DIR / class_name
        if p1_class_dir.is_dir():
            p1_readme = parse_readme_md(p1_class_dir / "Readme.md")
            p1_methods = parse_methods_md(p1_class_dir / "methods.md")

        # --- Phase 2 data ---
        p2_methods = {}
        p2_class_dir = PHASE2_DIR / class_name
        if p2_class_dir.is_dir():
            for md_file in p2_class_dir.glob("*.md"):
                method_name = md_file.stem
                p2_methods[method_name] = parse_method_override_md(md_file)

        # --- Phase 3 data ---
        p3_readme = {}
        p3_methods = {}
        p3_class_dir = PHASE3_DIR / class_name
        if p3_class_dir.is_dir():
            readme_path = p3_class_dir / "Readme.md"
            if readme_path.is_file():
                p3_readme = parse_readme_md(readme_path)
            for md_file in p3_class_dir.glob("*.md"):
                if md_file.name != "Readme.md":
                    method_name = md_file.stem
                    p3_methods[method_name] = parse_method_override_md(md_file)

        # --- Build class description ---
        # Start with Phase 1, override with Phase 3 (last-writer-wins)
        desc = build_class_description(base.get("description", ""), p1_readme, "auto")

        # Phase 3 overrides (last-writer-wins)
        for field in ("brief", "purpose", "details", "obtainedVia",
                       "codeExample", "alternatives", "relatedPreprocessors"):
            if field in p3_readme:
                desc[field] = p3_readme[field]

        # --- Constants ---
        constants = build_constants(p1_readme, "auto")
        p3_constants = build_constants(p3_readme, "manual")
        constants.update(p3_constants)  # Last-writer-wins per constant

        # --- Dynamic Constants ---
        dyn_constants = build_dynamic_constants(p1_readme, "auto")
        p3_dyn = build_dynamic_constants(p3_readme, "manual")
        dyn_constants.update(p3_dyn)

        # --- Common Mistakes (union merge) ---
        common_mistakes = build_common_mistakes(p1_readme, "auto")
        common_mistakes.extend(build_common_mistakes(p3_readme, "manual"))

        # --- Methods ---
        methods_output = {}
        all_method_names = set(base.get("methods", {}).keys())
        all_method_names.update(p1_methods.keys())
        all_method_names.update(p2_methods.keys())
        all_method_names.update(p3_methods.keys())

        for method_name in sorted(all_method_names):
            base_method = base.get("methods", {}).get(method_name, {})
            p1_method = p1_methods.get(method_name, {})
            p2_method = p2_methods.get(method_name, {})
            p3_method = p3_methods.get(method_name, {})

            # Start with base + Phase 1
            entry = build_method_entry(base_method, p1_method, "auto")

            # Apply Phase 2 overrides
            if p2_method:
                entry = merge_method_entries(entry, p2_method, "project")

            # Apply Phase 3 overrides
            if p3_method:
                entry = merge_method_entries(entry, p3_method, "manual")

            methods_output[method_name] = entry

        # --- Assemble class output ---
        output["classes"][class_name] = {
            "description": desc,
            "category": category,
            "constants": constants if constants else {},
            "dynamicConstants": dyn_constants if dyn_constants else {},
            "commonMistakes": common_mistakes if common_mistakes else [],
            "methods": methods_output,
        }

    # Write output
    output_path = OUTPUT_DIR / "api_reference.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    class_count = len(output["classes"])
    method_count = sum(
        len(c["methods"]) for c in output["classes"].values()
    )
    print(f"Merge complete:")
    print(f"  Classes: {class_count}")
    print(f"  Total methods: {method_count}")
    print(f"  Output: {output_path}")


# ===================================================================
# CLI
# ===================================================================

def main():
    parser = argparse.ArgumentParser(
        description="API Enrichment Pipeline CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    subparsers = parser.add_subparsers(dest="command", help="Subcommand to run")

    subparsers.add_parser(
        "phase0",
        help="Parse Doxygen XML → base JSON (mechanical, no AI)",
    )
    subparsers.add_parser(
        "prepare",
        help="Print worklist of unscanned classes/methods",
    )
    subparsers.add_parser(
        "merge",
        help="Merge all phases → output/api_reference.json",
    )

    args = parser.parse_args()

    if args.command == "phase0":
        run_phase0()
    elif args.command == "prepare":
        run_prepare()
    elif args.command == "merge":
        run_merge()
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
